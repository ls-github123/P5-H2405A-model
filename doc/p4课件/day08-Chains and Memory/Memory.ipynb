{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内存记忆 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内存记忆 \n",
    "\n",
    "```\n",
    "ConversationChatMessageHistory  会话记录\n",
    "ConversationBufferMemory        内存记忆\n",
    "ConversationBufferWindowMemory  可以设置记忆的条数\n",
    "ConversationEntityMemory        可以实体识别\n",
    "ConversationKGMemory            知识图谱\n",
    "ConversationSummaryMemory       总结摘要\n",
    "ConversationSummaryBufferMemory 总结摘要\n",
    "ConversationVectorStoreMemory   向量存储\n",
    "ConversationSQLDatabaseChainMemory\n",
    "ConversationFileMemory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.tongyi import Tongyi\n",
    "llm = Tongyi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"你好?\")\n",
    "history.add_user_message(\"请问丹麦的首都是哪里?\")\n",
    "history.add_ai_message(\"哥本哈根\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='你好'),\n",
       " AIMessage(content='你好?'),\n",
       " HumanMessage(content='请问丹麦的首都是哪里?'),\n",
       " AIMessage(content='哥本哈根')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好! 丹麦的首都是哥本哈根。'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我是人类！\\nAI: 你好，我是AI，有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 内存记忆\n",
    "from langchain.memory import  ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是人类！\")\n",
    "memory.chat_memory.add_ai_message(\"你好，我是AI，有什么可以帮助你的吗？\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 我想吃鸡肉\\nAI: 好的，我帮你找找鸡肉的做法\\nHuman: 我想吃鸭肉\\nAI: 好的，我帮你找找鸭肉的做法'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现一个最近的对话窗口，超过窗口条数的对话将被删除\n",
    "from langchain.memory import  ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "memory.save_context({\"input\":\"你好，我是人类!\"},{\"output\":\"你好，我是AI，有什么可以帮助你的吗？\"})\n",
    "memory.save_context({\"input\":\"我想吃鸡肉\"},{\"output\":\"好的，我帮你找找鸡肉的做法\"})\n",
    "memory.save_context({\"input\":\"我想吃鸭肉\"},{\"output\":\"好的，我帮你找找鸭肉的做法\"})\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"我想吃鸭肉\"},{\"output\":\"好的，我帮你找找鸭肉的做法\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建记忆实体概念清单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'胡八一': '', '王胖子': '', '雪莉杨': ''}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "\n",
    "_input = {\n",
    "    \"input\":\"胡八一和王胖子雪莉杨经常在一起冒险，合称盗墓铁三角.\"\n",
    "}\n",
    "\n",
    "memory.load_memory_variables(_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 胡八一和王胖子雪莉杨经常在一起冒险，合称盗墓铁三角.\\nAI: 听起来很刺激，我也想加入他们！',\n",
       " 'entities': {'胡八一': '胡八一是盗墓铁三角的一员，经常与王胖子和雪莉杨共同冒险。',\n",
       "  '王胖子': '王胖子是胡八一和雪莉杨的冒险伙伴，三人并称为“盗墓铁三角”。',\n",
       "  '雪莉杨': '雪莉杨是胡八一和王胖子的冒险伙伴，三人并称为“盗墓铁三角”。',\n",
       "  '盗墓铁三角': ''}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    _input,\n",
    "    {\n",
    "        \"output\":\"听起来很刺激，我也想加入他们！\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"铁三角是谁?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用知识图谱构建记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "memory = ConversationKGMemory(llm=llm,return_messages=True)\n",
    "\n",
    "memory.save_context( {\"input\":\"帮我找一下tomie\"}, {\"output\":\"对不起请问什么是tomie？\"})\n",
    "\n",
    "memory.save_context({\"input\":\"tomie是一个培训讲师\"},    {\"output\":\"好的，我知道了。\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"tomie是谁?\"})\n",
    "memory.load_memory_variables({\"input\":\"tomie是一个培训讲师\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomie']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_current_entities(\"tomie最喜欢做什么事?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.get_knowledge_triplets(\"tomie最喜欢做什么事\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomie']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_current_entities(\"tomie最喜欢打游戏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomie']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.get_current_entities(\"tomie是一个培训讲师\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='Tomie', predicate='is a', object_='training instructor')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.get_knowledge_triplets(\"tomie是一个培训讲师\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下张三\"},\n",
    "    {\"output\":\"对不起请问谁是张三？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"张三是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human asked the AI to find information about Zhang San, specifying that he is a training instructor. The AI acknowledged the information and will now search accordingly.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human requests to find information about Zhang San, specifying that he is a training instructor. The AI acknowledges the information and proceeds to search.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = memory.chat_memory.messages\n",
    "#print(messages)\n",
    "memory.predict_new_summary(messages,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=10,\n",
    "    return_messages=True\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"不需要资料了，谢谢\"},\n",
    "    {\"output\":\"好的，那我就不打扰你了。\"}\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 长时记忆\n",
    "\n",
    "通过向量数据库来存储之前的对话内容，有的向量数据库服务还提供自动摘要等，每次对话的时候，都会从向量数据库里查询最相关的文档或历史对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 帮我找一下tomie\n",
      "AI: 对不起请问什么是tomie？\n",
      "Human: tomie是一个培训讲师\n",
      "AI: 好的，我知道了。\n",
      "Human: 今天他要讲一门关于RAG的课程\n",
      "AI: 好的，我知道了。需要RAG的资料吗？\n",
      "Human: 不需要资料了，谢谢\n",
      "AI: 好的，那我就不打扰你了。\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"不需要资料了，谢谢\"},\n",
    "    {\"output\":\"好的，那我就不打扰你了。\"}\n",
    ")\n",
    "\n",
    "print(memory.buffer)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    memory.buffer.split(\"\\n\"),\n",
    "    DashScopeEmbeddings()\n",
    ")\n",
    "FAISS.save_local(vectorstore,\"test_faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss = FAISS.load_local(\"test_faiss\",DashScopeEmbeddings(),allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Human: tomie是一个培训讲师'),\n",
       " Document(page_content='AI: 对不起请问什么是tomie？'),\n",
       " Document(page_content='Human: 帮我找一下tomie'),\n",
       " Document(page_content='AI: 好的，那我就不打扰你了。')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss.similarity_search(\"tomie是什么职业?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 链上使用记忆\n",
    "\n",
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"你是一个机器人助理。\n",
    "{chat_history}\n",
    "user:{human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"chat_history\", \"human_input\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '中国的首都是哪里？', 'chat_history': '', 'text': '中国的首都是北京。'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"中国的首都是哪里？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '推荐一个旅游景点',\n",
       " 'chat_history': 'Human: 中国的首都是哪里？\\nAI: 中国的首都是北京。',\n",
       " 'text': '我推荐你去长城。长城是中国的标志性建筑之一，也是世界文化遗产，有着悠久的历史和壮丽的景色。无论是春天的花海、夏日的翠绿、秋天的金黄还是冬季的雪景，长城都有不同的魅力，会给你的旅行带来难忘的体验。同时，如果你对历史感兴趣，长城也是了解中国历史文化的重要场所。'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"推荐一个旅游景点\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '怎么去？',\n",
       " 'chat_history': 'Human: 中国的首都是哪里？\\nAI: 中国的首都是北京。\\nHuman: 推荐一个旅游景点\\nAI: 我推荐你去长城。长城是中国的标志性建筑之一，也是世界文化遗产，有着悠久的历史和壮丽的景色。无论是春天的花海、夏日的翠绿、秋天的金黄还是冬季的雪景，长城都有不同的魅力，会给你的旅行带来难忘的体验。同时，如果你对历史感兴趣，长城也是了解中国历史文化的重要场所。',\n",
       " 'text': '去长城的具体交通方式取决于你所在的位置。如果你在北京，有几种常见的方法可以到达：\\n\\n1. **公交**：可以乘坐877路、919路等公交车直达八达岭长城或慕田峪长城，车程大约需要2-3小时。\\n\\n2. **旅游巴士**：很多旅行社提供长城的一日游服务，包括往返接送，方便快捷。\\n\\n3. **地铁+公交**：先乘坐地铁到德胜门或者朱辛庄站，然后转乘前往长城的公交。\\n\\n4. **自驾**：如果你有车或者选择租车，也可以自驾前往，但需要注意路况和停车位。\\n\\n5. **长城专列/索道**：对于某些长城景区如慕田峪，还有缆车或索道可以选择，可以直达长城顶部，省力且视野开阔。\\n\\n记得提前规划行程，查看最新的交通信息，并根据自己的时间和偏好选择最适合的方式。'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"怎么去？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '给我讲一个笑话',\n",
       " 'history': [HumanMessage(content='给我讲一个笑话'),\n",
       "  AIMessage(content='当然，这里有一个笑话给您：为什么电脑永远不会感冒？因为它有“Windows”（窗户），但不开！笑点在于将电脑的“Windows”（微软操作系统）与建筑中的窗户进行了巧妙的双关。')],\n",
       " 'response': '当然，这里有一个笑话给您：为什么电脑永远不会感冒？因为它有“Windows”（窗户），但不开！笑点在于将电脑的“Windows”（微软操作系统）与建筑中的窗户进行了巧妙的双关。'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"给我讲一个笑话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '这个不好笑',\n",
       " 'history': [HumanMessage(content='给我讲一个笑话'),\n",
       "  AIMessage(content='当然，这里有一个笑话给您：为什么电脑永远不会感冒？因为它有“Windows”（窗户），但不开！笑点在于将电脑的“Windows”（微软操作系统）与建筑中的窗户进行了巧妙的双关。'),\n",
       "  HumanMessage(content='这个不好笑'),\n",
       "  AIMessage(content='哎呀，看来这个笑话没有逗笑您。那我再试试另一个：\\n\\n为什么数学书总是最不开心的？\\n因为它总是有很多问题！\\n\\n这个笑话是基于一个文字游戏，将“数学书里有很多问题”与“人有很多烦恼”进行了关联。希望这个能稍微让您微笑一下。如果还是不合您的口味，我可以继续寻找其他类型的幽默。')],\n",
       " 'response': '哎呀，看来这个笑话没有逗笑您。那我再试试另一个：\\n\\n为什么数学书总是最不开心的？\\n因为它总是有很多问题！\\n\\n这个笑话是基于一个文字游戏，将“数学书里有很多问题”与“人有很多烦恼”进行了关联。希望这个能稍微让您微笑一下。如果还是不合您的口味，我可以继续寻找其他类型的幽默。'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"这个不好笑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='给我讲一个笑话'),\n",
       " AIMessage(content='当然，这里有一个笑话给您：为什么电脑永远不会感冒？因为它有“Windows”（窗户），但不开！笑点在于将电脑的“Windows”（微软操作系统）与建筑中的窗户进行了巧妙的双关。'),\n",
       " HumanMessage(content='这个不好笑'),\n",
       " AIMessage(content='哎呀，看来这个笑话没有逗笑您。那我再试试另一个：\\n\\n为什么数学书总是最不开心的？\\n因为它总是有很多问题！\\n\\n这个笑话是基于一个文字游戏，将“数学书里有很多问题”与“人有很多烦恼”进行了关联。希望这个能稍微让您微笑一下。如果还是不合您的口味，我可以继续寻找其他类型的幽默。')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同一个链合并使用多个memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "#使用CoversationSummaryMemory对对话进行总结\n",
    "summay = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    input_key=\"input\"\n",
    ")\n",
    "#使用ConversationBufferMemory对对话进行缓存\n",
    "cov_memory = ConversationBufferMemory(\n",
    "    memory_key=\"history_now\",\n",
    "    input_key=\"input\",\n",
    ")\n",
    "\n",
    "memory = CombinedMemory(\n",
    "    memories=[summay, cov_memory],\n",
    ")\n",
    "\n",
    "TEMPLATE = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'.\n",
    "之前的对话摘要:\n",
    "{history}\n",
    "当前对话:\n",
    "{history_now}\n",
    "Human:{input}\n",
    "AI：\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=TEMPLATE,\n",
    "    input_variables=[\"history\", \"history_now\", \"input\"],\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'人类老爷，我真的不知道。'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"2024年NBA冠军是谁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多参数链增加记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "with open(\"doc/NBA新闻.txt\",encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "#切分文本\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size = 200,\n",
    "        chunk_overlap = 5\n",
    "    )\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "#使用openai的embedding\n",
    "    embddings = DashScopeEmbeddings()\n",
    "    #使用chroma向量存储\n",
    "    docssearch = Chroma.from_texts(\n",
    "        texts,\n",
    "        embddings,\n",
    "    )\n",
    "    query = \"公司有什么新策略?\"\n",
    "    docs = docssearch.similarity_search(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='在2024年NBA总决赛的最后一场比赛中，丹佛掘金在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。丹佛掘金队的成功主要归功于他们的领袖球员约基奇的出色表现。\\n在总决赛的五场比赛中，约基奇展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。约基奇在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。\\n在总决赛的最后一场比赛中，约基奇更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\\n约基奇荣获总决赛最有价值球员（MVP）毫无悬念。他在总决赛中的出色表现让他成为了不可或缺的球队核心，也让他获得了职业生涯中的首个总冠军。这一荣誉不仅是对他个人努力的认可，也是对他带领球队取得成功的肯定。\\n随着约基奇的崛起，丹佛掘金队在过去几个赛季中逐渐崭露头角。他的全面发展和领导能力使他成为了球队的核心和灵魂人物。通过这次总决赛的胜利，约基奇不仅实现了自己的篮球梦想，也为球队带来了无比的荣耀。\\n约基奇带领丹佛掘金赢得2024年NBA总冠军，并凭借出色的表现获得总决赛最有价值球员（MVP）的荣誉。他在总决赛期间的统治力和全面能力使他成为球队的核心，同时也展现了他的领导才能。这次胜利不仅是约基奇个人职业生涯的里程碑，也是丹佛掘金队迈向更高荣耀的关键一步。随着约基奇的领导，丹佛掘金队有望在未来继续取得更多的成功。'),\n",
       "  Document(page_content='在2024年NBA总决赛的最后一场比赛中，丹佛掘金在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。丹佛掘金队的成功主要归功于他们的领袖球员约基奇的出色表现。\\n在总决赛的五场比赛中，约基奇展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。约基奇在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。\\n在总决赛的最后一场比赛中，约基奇更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\\n约基奇荣获总决赛最有价值球员（MVP）毫无悬念。他在总决赛中的出色表现让他成为了不可或缺的球队核心，也让他获得了职业生涯中的首个总冠军。这一荣誉不仅是对他个人努力的认可，也是对他带领球队取得成功的肯定。\\n随着约基奇的崛起，丹佛掘金队在过去几个赛季中逐渐崭露头角。他的全面发展和领导能力使他成为了球队的核心和灵魂人物。通过这次总决赛的胜利，约基奇不仅实现了自己的篮球梦想，也为球队带来了无比的荣耀。\\n约基奇带领丹佛掘金赢得2024年NBA总冠军，并凭借出色的表现获得总决赛最有价值球员（MVP）的荣誉。他在总决赛期间的统治力和全面能力使他成为球队的核心，同时也展现了他的领导才能。这次胜利不仅是约基奇个人职业生涯的里程碑，也是丹佛掘金队迈向更高荣耀的关键一步。随着约基奇的领导，丹佛掘金队有望在未来继续取得更多的成功。')],\n",
       " 'human_input': '2024年NBA冠军是谁？',\n",
       " 'chat_history': [HumanMessage(content='2024年NBA冠军是谁？'),\n",
       "  AIMessage(content='2024年NBA冠军是丹佛掘金队。他们在总决赛中以总比分4-1击败了迈阿密热火队，成功夺得了球队历史上的第一个NBA总冠军。')],\n",
       " 'output_text': '2024年NBA冠军是丹佛掘金队。他们在总决赛中以总比分4-1击败了迈阿密热火队，成功夺得了球队历史上的第一个NBA总冠军。'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建问答对话链\n",
    "from langchain.chains.question_answering import  load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'，参考一下相关文档以及历史对话信息，AI会据此组织最终回答内容.\n",
    "{context}\n",
    "{chat_history}\n",
    "Human:{human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"chat_history\", \"human_input\"],\n",
    ")\n",
    "\n",
    "#使用ConversationBufferMemory对对话进行缓存 \n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"human_input\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "#加载对话链\n",
    "chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# chain.run(\"2024年NBA冠军是谁\")\n",
    "# chain({\"input_documents\":docs,\"human_input\":\"公司的营销策略是什么？\"})\n",
    "chain({\"input_documents\":docs,\"human_input\":\"2024年NBA冠军是谁？\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
