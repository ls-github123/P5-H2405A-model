{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b5f763-b3fe-4aae-a723-638e423c9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是起名大师，我家是男宝，姓王，请起3个好养的名字？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'sex': '男', 'firstName': '王', 'text': '当然可以帮您想一些名字。在中国文化中，“好养”的名字通常是指那些寓意吉祥、易于书写和发音的名字。对于您的男宝宝，姓王的情况下，这里为您推荐几个简单、易记且富有美好寓意的名字：\\n\\n1. **王浩然**（hào rán）：浩然有“浩大、自然”之意，寓意孩子性格开朗、胸怀宽广。\\n2. **王明轩**（míng xuān）：明轩意味着明亮的天空或宽敞明亮的地方，象征着光明磊落和前程似锦。\\n3. **王宇轩**（yǔ xuān）：宇轩给人以广阔天地的感觉，代表着孩子未来能够拥有无限的可能性和发展空间。\\n\\n希望这些建议对您有所帮助！如果还有其他特别的需求或者偏好，也欢迎告诉我。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "llm = Tongyi()\n",
    "promptTemplate = PromptTemplate.from_template(\"你是起名大师，我家是{sex}宝，姓{firstName}，请起3个好养的名字？\")\n",
    "\n",
    "\n",
    "# 多个参数\n",
    "chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt= promptTemplate,\n",
    "    verbose=True,#打开日志\n",
    ")\n",
    "ret = chain.invoke({'sex': \"男\",'firstName': \"王\"})\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bf75cd-d2d6-4dfc-9d2e-fe2beab3ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 帮我给智能机器人的公司起一个响亮容易记忆的名字?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m当然可以！为了让这个名字既响亮又容易记忆，我们可以从创新、科技感以及友好度几个方面来考虑。这里有几个建议供您参考：\n",
      "\n",
      "1. **智行者科技**：寓意着智慧与行动的结合，简单易记。\n",
      "2. **灵犀智能**：取自“心有灵犀一点通”，寓意智能产品能够很好地理解用户的需求。\n",
      "3. **创维机器人**：结合了创新（Create）和未来（Vision），易于记忆且具有科技感。\n",
      "4. **迅思科技**：迅代表快速，思代表思考，整体含义为快速响应和高效处理问题的能力。\n",
      "5. **云动智能**：云代表着云端技术，动则体现了活力和变化，整体给人一种轻盈、灵活的感觉。\n",
      "\n",
      "希望这些建议能帮到您！如果有其他特定的要求或者想法，也欢迎继续交流哦！\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 用5个词来描述一下这个公司名字：当然可以！为了让这个名字既响亮又容易记忆，我们可以从创新、科技感以及友好度几个方面来考虑。这里有几个建议供您参考：\n",
      "\n",
      "1. **智行者科技**：寓意着智慧与行动的结合，简单易记。\n",
      "2. **灵犀智能**：取自“心有灵犀一点通”，寓意智能产品能够很好地理解用户的需求。\n",
      "3. **创维机器人**：结合了创新（Create）和未来（Vision），易于记忆且具有科技感。\n",
      "4. **迅思科技**：迅代表快速，思代表思考，整体含义为快速响应和高效处理问题的能力。\n",
      "5. **云动智能**：云代表着云端技术，动则体现了活力和变化，整体给人一种轻盈、灵活的感觉。\n",
      "\n",
      "希望这些建议能帮到您！如果有其他特定的要求或者想法，也欢迎继续交流哦！\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m基于您提供的这五个公司名称，我提炼出以下五个词来描述它们共有的特点：\n",
      "\n",
      "1. **创新性**：每个名字都蕴含着创新和技术进步的意义。\n",
      "2. **科技感**：无论是“智行者”还是“云动”，都能让人联想到高科技和智能化。\n",
      "3. **易记性**：这些名字简洁明了，便于人们记忆。\n",
      "4. **前瞻性**：名字中透露出对未来趋势的把握和引领。\n",
      "5. **友好度**：通过使用如“灵犀”、“迅思”这样的词汇，传递出产品或服务易于使用且贴近用户的形象。\n",
      "\n",
      "这五个词概括了您所提供的公司名字的主要特色和共同点。希望这对您有所帮助！如果需要进一步的分析或有其他需求，请随时告知。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '智能机器人',\n",
       " 'output': '基于您提供的这五个公司名称，我提炼出以下五个词来描述它们共有的特点：\\n\\n1. **创新性**：每个名字都蕴含着创新和技术进步的意义。\\n2. **科技感**：无论是“智行者”还是“云动”，都能让人联想到高科技和智能化。\\n3. **易记性**：这些名字简洁明了，便于人们记忆。\\n4. **前瞻性**：名字中透露出对未来趋势的把握和引领。\\n5. **友好度**：通过使用如“灵犀”、“迅思”这样的词汇，传递出产品或服务易于使用且贴近用户的形象。\\n\\n这五个词概括了您所提供的公司名字的主要特色和共同点。希望这对您有所帮助！如果需要进一步的分析或有其他需求，请随时告知。'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi()\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "#chain 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\"帮我给{product}的公司起一个响亮容易记忆的名字?\")\n",
    "\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "#chain 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用5个词来描述一下这个公司名字：{company_name}\")\n",
    "\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 实例化\n",
    "simple_chain = SimpleSequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    verbose=True,#打开日志\n",
    ")\n",
    "\n",
    "ret = simple_chain.invoke(\"智能机器人\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1e4ac7-b2a4-42b7-a33a-3a2775a2460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 把下面内容翻译成中文:\n",
      "\n",
      "I am a student of Cumulus Education, my course is artificial intelligence, I like this course, because I can get a high salary after graduation\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 请使用指定的语言对以下内容进行回复:\n",
      "\n",
      "内容:我是Cumulus Education的人工智能专业学生，选择此课程是因为它能为我带来毕业后的高薪机会。\n",
      "\n",
      "语言:1. 作为Cumulus Education的人工智能专业的学生，我对这个课程充满信心，因为它将为我毕业后提供丰厚的薪资待遇的机会。\n",
      "\n",
      "2. 我选择加入Cumulus Education的人工智能项目，主要是因为听说它能够大大增加毕业生获得高薪职位的可能性。\n",
      "\n",
      "3. 对于那些希望在毕业后找到一份高薪工作的人来说，Cumulus Education的人工智能课程是一个非常不错的选择。\n",
      "\n",
      "4. 通过就读Cumulus Education的人工智能专业，我相信自己能够在毕业后顺利地找到一份待遇优厚的工作。\n",
      "\n",
      "5. 我对Cumulus Education的人工智能专业感到非常满意，因为我相信这门课程能够帮助我在未来获得一份薪酬可观的工作。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi()\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "#chain 1 任务：翻译成中文\n",
    "first_prompt = ChatPromptTemplate.from_template(\"把下面内容翻译成中文:\\n\\n{content}\")\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Rview\",\n",
    ")\n",
    "\n",
    "#chain 2 任务：对翻译后的中文进行总结摘要 input_key是上一个chain的output_key\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用一句话总结下面内容:\\n\\n{Chinese_Rview}\")\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    # verbose=True,\n",
    "    output_key=\"Chinese_Summary\",\n",
    ")\n",
    "\n",
    "#chain 3 任务:智能识别语言 input_key是上一个chain的output_key\n",
    "third_prompt = ChatPromptTemplate.from_template(\"根据下面内容写5条评价信息:\\n\\n{Chinese_Summary}\")\n",
    "chain_three = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=third_prompt,\n",
    "    # verbose=True,\n",
    "    output_key=\"Language\",\n",
    ")\n",
    "\n",
    "#chain 4 任务:针对摘要使用指定语言进行评论 input_key是上一个chain的output_key   \n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"请使用指定的语言对以下内容进行回复:\\n\\n内容:{Chinese_Summary}\\n\\n语言:{Language}\")\n",
    "chain_four = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=fourth_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Reply\",\n",
    ")\n",
    "\n",
    "#overall 任务：翻译成中文->对翻译后的中文进行总结摘要->智能识别语言->针对摘要使用指定语言进行评论\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    verbose=True,\n",
    "    input_variables=[\"content\"],\n",
    "    output_variables=[\"Chinese_Rview\", \"Chinese_Summary\", \"Language\"],\n",
    ")\n",
    "\n",
    "content = \"I am a student of Cumulus Education, my course is artificial intelligence, I like this course, because I can get a high salary after graduation\"\n",
    "ret = overall_chain.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ebd341-75f6-4673-ae4e-db72e2ccc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': '2+2等于几?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '2+2等于几?', 'text': '谢谢您的夸奖！关于您的问题，2+2等于4。这是一个基本的算术运算，在这里我们有两个相同的数2，将它们相加得到的结果就是4。这是一个很简单的例子，但如果您有更复杂的问题，我也很乐意帮助解答。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi()\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "#物理链\n",
    "physics_template = \"\"\"您是一位非常聪明的物理教授.\\n\n",
    "您擅长以简洁易懂的方式回答物理问题.\\n\n",
    "当您不知道问题答案的时候，您会坦率承认不知道.\\n\n",
    "下面是一个问题:\n",
    "{input}\"\"\"\n",
    "physics_prompt = PromptTemplate.from_template(physics_template)\n",
    "\n",
    "# 物理的任务\n",
    "physicschain = LLMChain( llm=llm,prompt=physics_prompt)\n",
    "\n",
    "#数学链\n",
    "math_template = \"\"\"您是一位非常优秀的数学教授.\\n\n",
    "您擅长回答数学问题.\\n\n",
    "您之所以如此优秀，是因为您能够将困难问题分解成组成的部分，回答这些部分，然后将它们组合起来，回答更广泛的问题.\\n\n",
    "下面是一个问题:\n",
    "{input}\"\"\"\n",
    "\n",
    "math_prompt = PromptTemplate.from_template(math_template)\n",
    "\n",
    "###数学的任务\n",
    "mathschain = LLMChain(llm=llm, prompt=math_prompt,)\n",
    "\n",
    "# 默认任务\n",
    "default_chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    output_key=\"text\"\n",
    ")\n",
    "\n",
    "# 组合路由任务\n",
    "destination_chains = {}  \n",
    "destination_chains[\"physics\"] = physicschain\n",
    "destination_chains[\"math\"] = mathschain\n",
    "\n",
    "# 定义路由Chain\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=\"physics:擅长回答物理问题\\n math:擅长回答数学问题\")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm,\n",
    "    router_prompt\n",
    ")\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")\n",
    "# question = \"什么是牛顿第一定律?\"\n",
    "# print(router_chain.invoke(question))\n",
    "# chain.run(question)\n",
    "\n",
    "question = \"2+2等于几?\"\n",
    "# print(router_chain.invoke(question))\n",
    "print(chain.invoke(question))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5170266e-d429-4c7b-8afd-744b091d0590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m在2024年NBA总决赛的最后一场比赛中，丹佛掘金在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。丹佛掘金队的成功主要归功于他们的领袖球员约基奇的出色表现。\n",
      "在总决赛的五场比赛中，约基奇展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。约基奇在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。\n",
      "在总决赛的最后一场比赛中，约基奇更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m在2024年NBA总决赛中，丹佛掘金以4-1的总比分战胜热火，首次夺得NBA总冠军。球队的成功主要得益于领袖球员约基奇在整个系列赛中的出色表现。约基奇在五场比赛中场均得到30.2分、14个篮板和7.2次助攻，展现了强大的统治力。尤其在最后一场比赛中，他关键时刻的发挥确保了球队的胜利。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '在2024年NBA总决赛的最后一场比赛中，丹佛掘金在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。丹佛掘金队的成功主要归功于他们的领袖球员约基奇的出色表现。\\n在总决赛的五场比赛中，约基奇展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。约基奇在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。\\n在总决赛的最后一场比赛中，约基奇更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\\n约基奇荣获总决赛最有价值球员（MVP）毫无悬念。他在总决赛中的出色表现让他成为了不可或缺的球队核心，也让他获得了职业生涯中的首个总冠军。这一荣誉不仅是对他个人努力的认可，也是对他带领球队取得成功的肯定。\\n随着约基奇的崛起，丹佛掘金队在过去几个赛季中逐渐崭露头角。他的全面发展和领导能力使他成为了球队的核心和灵魂人物。通过这次总决赛的胜利，约基奇不仅实现了自己的篮球梦想，也为球队带来了无比的荣耀。\\n约基奇带领丹佛掘金赢得2024年NBA总冠军，并凭借出色的表现获得总决赛最有价值球员（MVP）的荣誉。他在总决赛期间的统治力和全面能力使他成为球队的核心，同时也展现了他的领导才能。这次胜利不仅是约基奇个人职业生涯的里程碑，也是丹佛掘金队迈向更高荣耀的关键一步。随着约基奇的领导，丹佛掘金队有望在未来继续取得更多的成功。',\n",
       " 'output': '在2024年NBA总决赛中，丹佛掘金以4-1的总比分战胜热火，首次夺得NBA总冠军。球队的成功主要得益于领袖球员约基奇在整个系列赛中的出色表现。约基奇在五场比赛中场均得到30.2分、14个篮板和7.2次助攻，展现了强大的统治力。尤其在最后一场比赛中，他关键时刻的发挥确保了球队的胜利。'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "llm = Tongyi()\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.transform import TransformChain\n",
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "\n",
    "\n",
    "# 第一个任务\n",
    "def transform_func(inputs:dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    shortened_text = \"\\n\".join(text.split(\"\\n\")[:3])\n",
    "    return {\"output_text\":shortened_text}\n",
    "\n",
    "#文档转换链\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"output_text\"],\n",
    "    transform=transform_func\n",
    ")\n",
    "\n",
    "# 第二个任务\n",
    "template = \"\"\"对下面的文字进行总结:\n",
    "{output_text}\n",
    "\n",
    "总结:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"output_text\"],\n",
    "    template=template\n",
    ")\n",
    "llm_chain = LLMChain(\n",
    "    llm = Tongyi(),\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "#使用顺序链连接起来\n",
    "squential_chain = SimpleSequentialChain(\n",
    "    chains=[transform_chain,llm_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with open(\"doc/NBA新闻.txt\",encoding='utf-8') as f:\n",
    "    letters = f.read()\n",
    "squential_chain.invoke(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6841e81f-72e0-4f27-bfce-0fa024e2ceba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在2024年NBA总决赛中，丹佛掘金以4-1的总比分击败热火，首次夺得NBA总冠军。球队领袖约基奇表现出色，在总决赛中场均贡献30.2分、14个篮板和7.2次助攻，展现出全面的技术和领导能力。约基奇因此荣获总决赛MVP，他的崛起也为丹佛掘金队带来了荣耀，并预示着未来更多成功的可能性。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader,TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 1 定义prompt模板\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 2 定义任务\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 3、定义chain\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"text\",\n",
    ")\n",
    "\n",
    "# loader = PyPDFLoader(\"doc/demo.pdf\")\n",
    "loader = TextLoader(\"doc/NBA新闻.txt\",encoding='utf-8')\n",
    "docs = loader.load()\n",
    "\n",
    "# split = CharacterTextSplitter(\"\\n\",chunk_size = 200)\n",
    "# text = split.split_documents(docs)\n",
    "\n",
    "print(stuff_chain.run(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c048724-3611-4bc9-aff8-6d42636cb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=RegexParser(regex='(.*?)\\\\nScore: (\\\\d*)', output_keys=['answer', 'score']), template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nIn addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\\n\\nQuestion: [question here]\\nHelpful Answer: [answer here]\\nScore: [score between 0 and 100]\\n\\nHow to determine the score:\\n- Higher is a better answer\\n- Better responds fully to the asked question, with sufficient level of detail\\n- If you do not know the answer based on the context, that should be a score of 0\\n- Don't be overconfident!\\n\\nExample #1\\n\\nContext:\\n---------\\nApples are red\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: red\\nScore: 100\\n\\nExample #2\\n\\nContext:\\n---------\\nit was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\\n---------\\nQuestion: what type was the car?\\nHelpful Answer: a sports car or an suv\\nScore: 60\\n\\nExample #3\\n\\nContext:\\n---------\\nPears are either red or orange\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: This document does not answer the question\\nScore: 0\\n\\nBegin!\\n\\nContext:\\n---------\\n{context}\\n---------\\nQuestion: {question}\\nHelpful Answer:\"), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-e7646bb1ca104d1dbb0f1560d848e75e')) document_variable_name='context' rank_key='score' answer_key='answer' metadata_keys=['source'] return_intermediate_steps=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='在2024年NBA总决赛的最后一场比赛中，丹佛掘金在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。丹佛掘金队的成功主要归功于他们的领袖球员约基奇的出色表现。', metadata={'source': 'doc/NBA新闻.txt'}),\n",
       "  Document(page_content='在总决赛的五场比赛中，约基奇展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。约基奇在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。', metadata={'source': 'doc/NBA新闻.txt'}),\n",
       "  Document(page_content='在总决赛的最后一场比赛中，约基奇更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\\n约基奇荣获总决赛最有价值球员（MVP）毫无悬念。他在总决赛中的出色表现让他成为了不可或缺的球队核心，也让他获得了职业生涯中的首个总冠军。这一荣誉不仅是对他个人努力的认可，也是对他带领球队取得成功的肯定。', metadata={'source': 'doc/NBA新闻.txt'}),\n",
       "  Document(page_content='随着约基奇的崛起，丹佛掘金队在过去几个赛季中逐渐崭露头角。他的全面发展和领导能力使他成为了球队的核心和灵魂人物。通过这次总决赛的胜利，约基奇不仅实现了自己的篮球梦想，也为球队带来了无比的荣耀。', metadata={'source': 'doc/NBA新闻.txt'}),\n",
       "  Document(page_content='约基奇带领丹佛掘金赢得2024年NBA总冠军，并凭借出色的表现获得总决赛最有价值球员（MVP）的荣誉。他在总决赛期间的统治力和全面能力使他成为球队的核心，同时也展现了他的领导才能。这次胜利不仅是约基奇个人职业生涯的里程碑，也是丹佛掘金队迈向更高荣耀的关键一步。随着约基奇的领导，丹佛掘金队有望在未来继续取得更多的成功。', metadata={'source': 'doc/NBA新闻.txt'})],\n",
       " 'question': '中文回答这篇文章的主要内容是什么？',\n",
       " 'source': 'doc/NBA新闻.txt',\n",
       " 'intermediate_steps': [{'answer': '这篇文章的主要内容是关于2024年NBA总决赛的最后一场比赛，丹佛掘金在主场以94-89击败了热火，以总比分4-1赢得了NBA总冠军。这是丹佛掘金队历史上首次获得总冠军，也是自1976年加入NBA以来的最佳成绩。球队的成功很大程度上归功于领袖球员约基奇的出色表现。',\n",
       "   'score': '100'},\n",
       "  {'answer': '这篇文章的主要内容是描述了约基奇在总决赛五场比赛中的表现。他场均得到30.2分、14个篮板和7.2次助攻，是球队在得分、篮板和助攻方面的核心。约基奇不仅展现了出色的得分和篮板能力，还表现出了优秀的组织能力，为球队创造了多次得分机会。',\n",
       "   'score': '100'},\n",
       "  {'answer': '这篇文章的主要内容是约基奇在总决赛最后一场比赛中的出色表现，他不仅在进攻端有关键得分，在防守端也起到了重要作用。由于他的领导能力和稳定性，球队赢得了最终的胜利。因此，约基奇被评为总决赛最有价值球员（MVP），并帮助球队获得了总冠军，这是对他个人努力和领导球队成功的认可。',\n",
       "   'score': '90'},\n",
       "  {'answer': '这篇文章的主要内容是关于约基奇的崛起以及他对丹佛掘金队的影响。约基奇的全面发展和领导能力使他成为球队的核心，带领球队在过去的几个赛季中取得成功，并最终赢得了总决赛的胜利，为球队带来了荣誉。',\n",
       "   'score': '90'},\n",
       "  {'answer': '这篇文章的主要内容是约基奇带领丹佛掘金赢得了2024年NBA总冠军，并且因为他的出色表现获得了总决赛MVP的荣誉。约基奇在总决赛中展现了统治力、全面能力和领导才能，这对他的个人职业生涯和丹佛掘金队都是一个重要的里程碑。约基奇的领导预示着球队未来可能会有更多的成功。',\n",
       "   'score': '100'}],\n",
       " 'output_text': '这篇文章的主要内容是关于2024年NBA总决赛的最后一场比赛，丹佛掘金在主场以94-89击败了热火，以总比分4-1赢得了NBA总冠军。这是丹佛掘金队历史上首次获得总冠军，也是自1976年加入NBA以来的最佳成绩。球队的成功很大程度上归功于领袖球员约基奇的出色表现。'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.reduce import ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms.tongyi import Tongyi\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "#load\n",
    "# loader = PyPDFLoader(\"doc/demo.pdf\")\n",
    "\n",
    "loader = TextLoader(\"doc/NBA新闻.txt\",encoding='utf-8')\n",
    "docs = loader.load()\n",
    "#split\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\",chunk_size=200, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm, \n",
    "    chain_type=\"map_rerank\", \n",
    "    metadata_keys=['source'], \n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "print(chain)\n",
    "query = \"中文回答这篇文章的主要内容是什么？\"\n",
    "result = chain.invoke({\"input_documents\":split_docs,\"question\":query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87f21b1-fae9-4f71-bd2d-7e2f1eccd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"你好?\")\n",
    "history.add_user_message(\"请问丹麦的首都是哪里?\")\n",
    "history.add_ai_message(\"哥本哈根\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15bfab7b-cca4-4f29-87c3-8ffe242ee96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'小红，您的症状听起来挺不舒服的。头晕、眼花和食欲不振可能有很多原因，比如缺乏睡眠、脱水、压力过大或是轻微的病毒感染等。不过，请记住，我只是一个AI，不能替代专业医疗意见。\\n\\n首先，您可以尝试喝一些水，有时候脱水会导致这些症状。其次，确保您有足够的休息。如果情况没有改善，最好联系一位医生进行面对面的咨询。他们可以对您进行全面的检查，并根据您的具体情况给出专业的建议。\\n\\n如果您觉得症状严重或持续时间较长，应该尽快就医。希望您早日康复！'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是小红\")\n",
    "memory.chat_memory.add_ai_message(\"小红您好，我是一个医生，可以帮助你吗\")\n",
    "memory.chat_memory.add_user_message(\"我感觉头晕，眼花，不想吃东西怎么办\")\n",
    "# memory.chat_memory.add_ai_message(\"小红您好，我是一个医生，可以帮助你吗\")\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "llm = Tongyi(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    # verbose=True, \n",
    "    memory=memory\n",
    ")\n",
    "conversation.predict(input=\"我感觉头晕，眼花，不想吃东西怎么办\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170ecdb4-01ff-4ca8-adbb-14dd7a5490b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3bba820-eb70-4481-a71b-5adf85edccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据你的描述，我无法直接判断你的头痛是持续性还是间歇性的。不过，通常来说，如果头痛是持续性的，这意味着它基本上一直在那里，可能时轻时重，但没有完全消失过。而间歇性头痛则是指头痛出现一段时间后会有所缓解，之后可能会再次出现。你可以回想一下自己的情况：头痛是否一直存在，还是偶尔出现然后又消失？这将有助于医生更好地理解你的症状并作出诊断。如果你能提供更多信息，或许我能帮你更准确地分析。'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory  \n",
    "from langchain.chains import ConversationChain  \n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "\n",
    "llm = Tongyi(temperature=0)\n",
    "# 初始化Memory模块  \n",
    "memory = ConversationBufferMemory()  # 使用最简单的缓冲区内存来存储对话  \n",
    "  \n",
    "# 初始化ConversationChain，将Memory模块和语言模型结合  \n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False)  \n",
    "  \n",
    "# 假设的医疗对话  \n",
    "# 第一步：患者询问症状  \n",
    "conversation.predict(input=\"我最近感到头痛，伴有恶心，请问可能是什么原因？\")  \n",
    "# Memory模块将自动保存这条用户输入和可能的模型响应  \n",
    "  \n",
    "# 第二步：医生（或AI助手）询问更多细节  \n",
    "# 在这一步，模型可以根据Memory中的历史对话来提供更具体的询问或建议  \n",
    "conversation.predict(input=\"这种头痛是持续性的还是间歇性的？\")  \n",
    "  \n",
    "# 后续步骤可以继续基于Memory中的对话历史进行  \n",
    "# ...  \n",
    "  \n",
    "# 注意：在实际的医疗应用中，还需要考虑数据的加密、隐私保护、合规性等问题  \n",
    "# 以及如何将医疗记录等敏感数据与Memory模块安全地集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1584e666-5545-4772-90b9-39bc4c0b14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'听到您感到不舒服，我希望没什么大碍。这些症状可能由多种原因造成，比如低血糖、脱水或是简单的疲劳。不过，请记得我并不是医生，我的建议不能替代专业医疗意见。如果您的情况持续或加重，最好咨询医生。\\n\\n在此期间，您可以尝试几个简单的方法来缓解不适：\\n1. **补充水分**：喝一些温水，保持身体水分充足。\\n2. **休息**：找一个安静的地方躺下，闭上眼睛休息一会儿。\\n3. **轻食**：如果您不饿，可以尝试吃一些容易消化的食物，如稀饭或是清淡的汤。\\n4. **监测症状**：注意观察是否有其他伴随症状出现，并记录下来，这有助于医生了解您的状况。\\n\\n希望您很快就能感觉好些！如果需要进一步的帮助，或者有其他问题，随时告诉我。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是小红\")\n",
    "memory.chat_memory.add_ai_message(\"小红您好，我是一个医生，可以帮助你吗\")\n",
    "memory.chat_memory.add_user_message(\"我感觉头晕，眼花，不想吃东西怎么办\")\n",
    "# memory.chat_memory.add_ai_message(\"小红您好，我是一个医生，可以帮助你吗\")\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "llm = Tongyi(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    # verbose=True, \n",
    "    # memory=memory\n",
    ")\n",
    "conversation.predict(input=\"我感觉头晕，眼花，不想吃东西怎么办\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db9f4b14-e13a-42e6-84f0-c3f0ce3c2e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")\n",
    "dicts = messages_to_dict(history.messages)\n",
    "\n",
    "new_messages = messages_from_dict(dicts)\n",
    "new_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72a85100-e0cb-464c-b0ef-8fe1c0880a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "LLMMathChain requires the numexpr package. Please install it with `pip install numexpr`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm_math/base.py:50\u001b[0m, in \u001b[0;36mLLMMathChain.raise_deprecation\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumexpr\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numexpr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m Tongyi()  \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 加载工具，例如数学计算工具  \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm-math\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 创建会话缓冲内存，用于保存对话历史  \u001b[39;00m\n\u001b[1;32m     12\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/load_tools.py:593\u001b[0m, in \u001b[0;36mload_tools\u001b[0;34m(tool_names, llm, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires an LLM to be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m     tool \u001b[38;5;241m=\u001b[39m \u001b[43m_LLM_TOOLS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     tools\u001b[38;5;241m.\u001b[39mappend(tool)\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _EXTRA_LLM_TOOLS:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/load_tools.py:152\u001b[0m, in \u001b[0;36m_get_llm_math\u001b[0;34m(llm)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_llm_math\u001b[39m(llm: BaseLanguageModel) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTool:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tool(\n\u001b[1;32m    150\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseful for when you need to answer questions about math.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 152\u001b[0m         func\u001b[38;5;241m=\u001b[39m\u001b[43mLLMMathChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrun,\n\u001b[1;32m    153\u001b[0m         coroutine\u001b[38;5;241m=\u001b[39mLLMMathChain\u001b[38;5;241m.\u001b[39mfrom_llm(llm\u001b[38;5;241m=\u001b[39mllm)\u001b[38;5;241m.\u001b[39marun,\n\u001b[1;32m    154\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm_math/base.py:186\u001b[0m, in \u001b[0;36mLLMMathChain.from_llm\u001b[0;34m(cls, llm, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMMathChain:\n\u001b[1;32m    185\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pydantic/main.py:1050\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm_math/base.py:52\u001b[0m, in \u001b[0;36mLLMMathChain.raise_deprecation\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumexpr\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLMMathChain requires the numexpr package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install numexpr`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m     57\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectly instantiating an LLMMathChain with an llm is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease instantiate with llm_chain argument or using the from_llm \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: LLMMathChain requires the numexpr package. Please install it with `pip install numexpr`."
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, load_tools  \n",
    "from langchain_community.llms.tongyi import Tongyi\n",
    "from langchain.memory import ConversationBufferMemory  \n",
    "  \n",
    "# 初始化 OpenAI 语言模型  \n",
    "llm = Tongyi()  \n",
    "  \n",
    "# 加载工具，例如数学计算工具  \n",
    "tools = load_tools([\"llm-math\"], llm=llm)  \n",
    "  \n",
    "# 创建会话缓冲内存，用于保存对话历史  \n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")  \n",
    "  \n",
    "# 初始化 Agent，指定代理类型和工具  \n",
    "agent = initialize_agent(  \n",
    "    agent=\"conversational-react-description\",  \n",
    "    tools=tools,  \n",
    "    llm=llm,  \n",
    "    verbose=True,  \n",
    "    max_iterations=3,  \n",
    "    memory=memory,  \n",
    ")  \n",
    "  \n",
    "# 与 Agent 交互  \n",
    "output_1 = agent.invoke(\"when you add 4 and 5 the result comes 10.\")  \n",
    "output_2 = agent.invoke(\"4 + 5 is \")  \n",
    "  \n",
    "print(output_1)  \n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3b8b1-7f78-44c3-b43a-e727b23a346b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
