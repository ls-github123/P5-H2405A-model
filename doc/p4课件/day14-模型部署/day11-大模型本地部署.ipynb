{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b54a184-b1a0-4125-8578-729c9410ff58",
   "metadata": {},
   "source": [
    "# æ¨¡å‹ç¤¾åŒº\n",
    "\n",
    "## HuggingFace\n",
    "\n",
    "å®˜ç½‘ï¼šhttps://huggingface.co/\n",
    "\n",
    "HuggingFace æ˜¯ä¸€ä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸçš„å¼€æºç¤¾åŒºå’Œå¹³å°ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—å¼ºå¤§çš„å·¥å…·ã€åº“å’Œé¢„è®­ç»ƒæ¨¡å‹ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿæ„å»ºå’Œéƒ¨ç½²è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ã€‚HuggingFace å¹³å°çš„ä¸»è¦ç»„æˆéƒ¨åˆ†å’Œç‰¹ç‚¹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **Transformers åº“**ï¼šHuggingFace çš„ Transformers åº“æ˜¯å…¶æœ€è‘—åå’Œæ ¸å¿ƒçš„éƒ¨åˆ†ã€‚å®ƒæä¾›äº†å¹¿æ³›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚BERTã€GPTã€RoBERTaç­‰ï¼‰çš„å®ç°ï¼Œå¹¶æä¾›æ˜“äºä½¿ç”¨çš„APIï¼Œç”¨äºè¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æ–‡æœ¬ç”Ÿæˆç­‰å„ç§ NLP ä»»åŠ¡ã€‚Transformers åº“æ”¯æŒå¤šç§ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¦‚PyTorchå’ŒTensorFlowã€‚\n",
    "2. **æ¨¡å‹æ¶æ„å’Œä¼˜åŒ–æ–¹æ³•**ï¼šHuggingFace æä¾›äº†å„ç§ç”¨äºæ„å»ºå’Œä¼˜åŒ– NLP æ¨¡å‹çš„æ¶æ„å’Œæ–¹æ³•ï¼ŒåŒ…æ‹¬ç”¨äºåºåˆ—åˆ†ç±»ã€åºåˆ—æ ‡æ³¨ã€æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡çš„æ¨¡å‹æ¶æ„å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥åŠç”¨äºæ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–çš„æŠ€æœ¯ï¼Œå¦‚å­¦ä¹ ç‡è°ƒåº¦ã€æƒé‡è¡°å‡ç­‰ã€‚\n",
    "3. **æ•°æ®é›†å’ŒæŒ‡æ ‡**ï¼šHuggingFace æä¾›äº†å¤§é‡çš„ NLP æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚è¿™äº›æ•°æ®é›†æ¶µç›–äº†å„ç§ä¸åŒçš„ä»»åŠ¡å’Œè¯­è¨€ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æç­‰ã€‚æ­¤å¤–ï¼ŒHuggingFace è¿˜æä¾›äº†å¸¸ç”¨çš„è¯„ä¼°æŒ‡æ ‡å’Œè¯„ä¼°æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œè¯„ä¼°å’Œæ¯”è¾ƒã€‚\n",
    "4. **æ¨¡å‹è®­ç»ƒå’Œéƒ¨ç½²å·¥å…·**ï¼šHuggingFace æä¾›äº†ç”¨äºæ¨¡å‹è®­ç»ƒå’Œéƒ¨ç½²çš„å·¥å…·å’Œåº“ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°è¿›è¡Œæ¨¡å‹è®­ç»ƒã€å¾®è°ƒå’Œéƒ¨ç½²ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡ä½¿ç”¨ HuggingFace çš„ Trainer ç±»ï¼Œç”¨æˆ·å¯ä»¥æ›´ä¾¿æ·åœ°é…ç½®å’Œæ‰§è¡Œæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚\n",
    "5. **æ¨¡å‹åˆ†äº«å’Œç¤¾åŒº**ï¼šHuggingFace å¹³å°é¼“åŠ±ç”¨æˆ·åˆ†äº«å’Œäº¤æµæ¨¡å‹ã€ä»£ç å’Œç»éªŒã€‚ç”¨æˆ·å¯ä»¥åœ¨ HuggingFace çš„æ¨¡å‹ä»“åº“ä¸­å‘å¸ƒå’Œå…±äº«è‡ªå·±çš„æ¨¡å‹ï¼Œå¹¶ä»ç¤¾åŒºä¸­è·å–æ¨¡å‹ã€ä»£ç å’Œåº”ç”¨æ¡ˆä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fdae68-9ab7-4354-a4ca-450fedbc38f9",
   "metadata": {},
   "source": [
    "## ModelScope\n",
    "\n",
    "å®˜ç½‘ï¼šhttps://www.modelscope.cn\n",
    "\n",
    "é­”æ­ç¤¾åŒºModelScopeæ˜¯ä¸€ä¸ªç”±é˜¿é‡Œè¾¾æ‘©é™¢æ¨å‡ºçš„å¼€æºæ¨¡å‹æœåŠ¡å¹³å°ï¼Œå…¶ä¸»è¦åŠŸèƒ½å’Œç›®çš„å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. æ¨¡å‹å…±äº«ä¸æ¢ç´¢ï¼š ModelScopeæ±‡é›†äº†å„é¢†åŸŸæœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³è¯†åˆ«ç­‰ã€‚ç”¨æˆ·å¯ä»¥åœ¨å¹³å°ä¸Šå‘ç°å’Œæ¢ç´¢è¿™äº›æ¨¡å‹ï¼Œäº†è§£å…¶ç‰¹æ€§å’Œæ€§èƒ½ã€‚\n",
    "2. ä¸€ç«™å¼æœåŠ¡ï¼š æä¾›ä»æ¨¡å‹æ¢ç´¢ã€æ¨ç†ã€è®­ç»ƒåˆ°éƒ¨ç½²å’Œåº”ç”¨çš„ä¸€ç«™å¼æœåŠ¡ã€‚ç”¨æˆ·ä¸ä»…å¯ä»¥ä½“éªŒé¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚å¯¹æ¨¡å‹è¿›è¡Œå®šåˆ¶å’Œè®­ç»ƒï¼Œå¹¶æ–¹ä¾¿åœ°å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­ã€‚\n",
    "3. æ˜“ç”¨æ€§å’Œçµæ´»æ€§ï¼š ModelScopeæ—¨åœ¨ä¸ºæ³›AIå¼€å‘è€…æä¾›çµæ´»ã€æ˜“ç”¨ã€ä½æˆæœ¬çš„æ¨¡å‹æœåŠ¡äº§å“ã€‚ç”¨æˆ·æ— éœ€é¢å¤–éƒ¨ç½²å¤æ‚çš„ç¯å¢ƒï¼Œå°±å¯ä»¥åœ¨å¹³å°ä¸Šç›´æ¥ä½¿ç”¨å„ç§æ¨¡å‹ï¼Œé™ä½äº†ä½¿ç”¨å’Œå¼€å‘AIæ¨¡å‹çš„é—¨æ§›ã€‚\n",
    "4. å¼€æºä¸åˆä½œï¼š ä½œä¸ºä¸€æ¬¾å¼€æºå¹³å°ï¼ŒModelScopeé¼“åŠ±ç¤¾åŒºæˆå‘˜å‚ä¸æ¨¡å‹çš„å¼€å‘ã€æ”¹è¿›å’Œåˆ†äº«ã€‚é€šè¿‡å…±åŒåˆä½œï¼Œæ¨åŠ¨AIæŠ€æœ¯çš„å‘å±•å’Œåˆ›æ–°ã€‚\n",
    "5. æ™ºèƒ½ä½“å¼€å‘æ¡†æ¶ï¼š ModelScopeè¿˜æ¨å‡ºäº†ModelScope-Agentå¼€å‘æ¡†æ¶ï¼Œå¦‚MSAgent-Qwen-7Bï¼Œå…è®¸ç”¨æˆ·æ‰“é€ å±äºè‡ªå·±çš„æ™ºèƒ½ä½“ã€‚è¿™ä¸ªæ¡†æ¶æä¾›äº†ä¸°å¯Œçš„ç¯å¢ƒé…ç½®é€‰é¡¹ï¼Œæ”¯æŒå•å¡è¿è¡Œï¼Œå¹¶æœ‰ä¸€å®šçš„æ˜¾å­˜è¦æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4458ce0-abca-4cd6-8f56-ca7104879b2f",
   "metadata": {},
   "source": [
    "## AutoDL \n",
    "- https://www.autodl.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173092c-8a21-46f4-8494-6680078c75da",
   "metadata": {},
   "source": [
    "### å­¦æœ¯åŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becefba-962f-4f3c-9a7b-79091282f6af",
   "metadata": {},
   "source": [
    "- è®¿é—®githubç­‰å¤–ç½‘é€Ÿåº¦æ…¢æ—¶å¯å¼€å¯å­¦æœ¯åŠ é€Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00474b6-eecc-458c-b55b-28a6296239e0",
   "metadata": {},
   "source": [
    "```\n",
    "å¼€å¯å­¦æœ¯åŠ é€Ÿ\n",
    "source /etc/network_turbo\n",
    "\n",
    "å–æ¶ˆå­¦æœ¯åŠ é€Ÿï¼Œå¦‚æœä¸å†éœ€è¦å»ºè®®å…³é—­å­¦æœ¯åŠ é€Ÿï¼Œå› ä¸ºè¯¥åŠ é€Ÿå¯èƒ½å¯¹æ­£å¸¸ç½‘ç»œé€ æˆä¸€å®šå½±å“\n",
    "unset http_proxy && unset https_proxy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8a811-2939-4d65-8a0d-8cf47acd19a5",
   "metadata": {},
   "source": [
    "### ç£ç›˜æ‰©å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb42c9-aa72-49fe-b6bd-0ecb28c36f3f",
   "metadata": {},
   "source": [
    "- è¿™é‡Œæ‰©å®¹äº†100Gï¼Œå®¹é‡è‡ªåŠ¨æ‰©å±•åˆ°/root/autodl-tmpç›®å½•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d1766-8b4e-4ba3-9567-76dfb1b3b89c",
   "metadata": {},
   "source": [
    "```\n",
    "å­˜å‚¨ï¼š\n",
    "  ç³» ç»Ÿ ç›˜/               ï¼š32% 9.5G/30G\n",
    "  æ•° æ® ç›˜/root/autodl-tmpï¼š1% 8.0K/150G\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f661b-efbd-45f5-ac92-4a0839d50d3e",
   "metadata": {},
   "source": [
    "- è‹¥ä½¿ç”¨è¿‡ç¨‹ä¸­å‘ç°ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå¯å…³æœºåæ‰©å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e3ff5-f814-4240-8216-ecc400928355",
   "metadata": {},
   "source": [
    "<img src=\"img/xx_20240803100734.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb88bc-203c-4872-8907-ca5f56dac773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb57015e-f9ee-4f74-bb05-ab8ce3c0accd",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/dd_20240803100507.png\" style=\"margin-left: 0px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74907e9-d228-40cc-8a23-a147cac3d57b",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ollama3éƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹\n",
    "Ollama æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œå®ƒå…è®¸ç”¨æˆ·åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸ªé¡¹ç›®ç®€åŒ–äº†åœ¨ä¸ªäººç”µè„‘æˆ–æœåŠ¡å™¨ä¸Šéƒ¨ç½²å’Œè¿è¡ŒåƒLLaMAè¿™æ ·çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿‡ç¨‹ã€‚å¦‚æœä½ æƒ³è¦ä½¿ç”¨ Ollama éƒ¨ç½²æœ¬åœ°çš„å¤§æ¨¡å‹\n",
    "\n",
    "- ç”±äºå­¦ç”Ÿç”µè„‘ç³»ç»Ÿä¸ç»Ÿä¸€ï¼Œæœ‰çš„æ˜¯windowsï¼Œæœ‰çš„æ˜¯mac,è¿˜æœ‰çš„æ˜¯Ubautu\n",
    "- è¿™å‡ ä¸ªç³»ç»Ÿä¸­ï¼ŒUbautué‡åˆ°çš„é—®é¢˜æ¯”è¾ƒå°‘ï¼Œwindowså¯èƒ½é‡åˆ°çš„é—®é¢˜æœ€å¤š\n",
    "- ç»™å­¦ç”Ÿä¸€å®šæ—¶é—´è‡ªè¡Œå®‰è£…ï¼Œé‡åˆ°é—®é¢˜é¦–å…ˆå°è¯•è‡ªè¡Œæœç´¢è§£å†³"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6431b8-6642-4b2c-9e84-709c085dc02f",
   "metadata": {},
   "source": [
    "ä¸‹è½½å¯¹åº”ç³»ç»Ÿçš„ç‰ˆæœ¬\n",
    "- https://ollama.com/download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc3ca7-b46e-4a56-924a-6e8fa70d1423",
   "metadata": {},
   "source": [
    "### windowså®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45029dec-0ea4-4d5e-b567-8c3bfb24f4e5",
   "metadata": {},
   "source": [
    "- ä¸‹è½½å®Œæ¯•åï¼ŒåŒå‡»æ‰§è¡Œå®‰è£…\n",
    "- å®‰è£…å®Œæˆååœ¨cmdä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå®‰è£…å…·ä½“æŸä¸ªå¤§æ¨¡å‹\n",
    "- å¦‚æœæœ¬åœ°ä¸å­˜åœ¨æ¨¡å‹ï¼Œåˆ™ä¼šå…ˆè¡Œä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48621d6-c7ec-49f1-b5c5-18967612bf07",
   "metadata": {},
   "source": [
    "linuxå®‰è£…\n",
    "\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "<img src=\"img/lla_20240801143507.png\" style=\"margin-left: 0px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746bf65-9804-4ed0-8b43-ab19c2eed6a0",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "PS C:\\> ollama list\n",
    "NAME                    ID              SIZE    MODIFIED\n",
    "llama2-chinese:13b      990f930d55c5    7.4 GB  6 weeks ago\n",
    "gemma:latest            a72c7f4d0a15    5.0 GB  6 weeks ago\n",
    "qwen2:latest            e0d4e1163c58    4.4 GB  6 weeks ago\n",
    "llama3:latest           365c0bd3c000    4.7 GB  6 weeks ago\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce344a-833c-45d1-a8d7-b57e07c1a9c0",
   "metadata": {},
   "source": [
    "### æµ‹è¯•æœåŠ¡æ˜¯å¦å¯åŠ¨\n",
    "- http://localhost:11434/api/tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46527ea5-c7d3-4277-9783-a42333cc91a1",
   "metadata": {},
   "source": [
    "æ­£å¸¸çŠ¶æ€å¦‚ä¸‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c22676-42e0-42e0-bb3b-639a3ac5a32e",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/lla_20240801145720.png\" style=\"margin-left: 0px\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama serve\n",
    "ollama run llama3.1\n",
    "\n",
    "æµ‹è¯•ä»£ç \n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "  \"model\": \"llama3.1\",\n",
    "  \"messages\": [\n",
    "    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d63a7e-0910-42a6-8269-abd12679193b",
   "metadata": {},
   "source": [
    "### llama3æ”¯æŒçš„å¤§æ¨¡å‹\n",
    "- https://github.com/ollama/ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb60fe-375b-415b-ac56-474943b753fb",
   "metadata": {},
   "source": [
    "## REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18daf6d-5fa2-432c-8c24-bef6a2771581",
   "metadata": {},
   "source": [
    "- windowsä¸Šå¯ä»¥å®‰è£…gitï¼Œè¿™æ ·å°±å¯ä»¥ä½¿ç”¨curlå‘½ä»¤ï¼Œä»¥æ–¹ä¾¿éªŒè¯ollamaæœåŠ¡æ˜¯å¦æ­£å¸¸å¯åŠ¨\n",
    "- åˆå­¦è€…ä¸è¦WSLä¸­è¿è¡Œï¼Œå› ä¸ºç½‘ç»œçš„åŸå› é»˜è®¤wslä¸­æ— æ³•è®¿é—®æœ¬åœ°ä¸Šå®‰è£…çš„ollamaæœåŠ¡\n",
    "- åˆå­¦è€…ä¹Ÿä¸è¦åœ¨dockerä¸­è®¿é—®ä¸»æœºä¸Šçš„ollamaï¼Œå¾ˆå¯èƒ½å› ä¸ºç½‘ç»œä¸é€šè€Œæ— æ³•è®¿é—®\n",
    "- mac,ubautuç³»ç»Ÿå¯ç›´æ¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e20f8e-acc4-486b-ba31-0c2be2ec7658",
   "metadata": {},
   "source": [
    "### Generate a response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5235b-d860-428b-aa69-291e33907ca9",
   "metadata": {},
   "source": [
    " \n",
    "```\n",
    "curl http://localhost:11434/api/generate -d '{\n",
    "    \"model\": \"llama3\",\n",
    "    \"prompt\":\"Why is the sky blue?\"\n",
    "    }'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadf395-a0e6-42ea-8e57-e8136d90a451",
   "metadata": {},
   "source": [
    "### Chat with a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecf8a1-6633-4ad1-99eb-95764be8390a",
   "metadata": {},
   "source": [
    "```\n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "    \"model\": \"llama3\",\n",
    "    \"messages\": [\n",
    "        { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "    ]\n",
    "    }'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e901b-d594-4120-8525-81e78e12d31b",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨å·¥å…·è®¿é—®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2792967-8b8a-4d39-8266-9e462d3e90f5",
   "metadata": {},
   "source": [
    "### apipost\n",
    "- https://www.apipost.cn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495f7a4-8b58-4302-818c-4f09285c40bf",
   "metadata": {},
   "source": [
    "<img src=\"img/api_20240802082845.png\" style=\"margin-left: 0px\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0efa6-5102-47f8-a1ad-346ef352dad0",
   "metadata": {},
   "source": [
    "ä½¿ç”¨apipost/postman \n",
    "apipost è®¾ç½® -- è¶…æ—¶æ—¶é—´è¦è®¾ç½®é•¿ä¸€äº›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0e790-53b5-4869-86c0-1d19cc2eb788",
   "metadata": {},
   "source": [
    "<img src=\"img/ll_20240802082504.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b2c4a-3369-4d82-9651-edf1dbbb7c64",
   "metadata": {},
   "source": [
    "### postman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd375804-7fef-4e4f-a189-539e56ae6dd9",
   "metadata": {},
   "source": [
    "- https://www.postman.com/downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f6d30-3a4a-48ff-a6d4-5fd5029c3c7e",
   "metadata": {},
   "source": [
    "<img src=\"img/post_20240802083145.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f945374-f9c6-48e9-baf6-b53d7b3ae00d",
   "metadata": {},
   "source": [
    "<img src=\"img/post_20240802084235.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5d349-89ee-4e34-b7ea-b394e68cfa04",
   "metadata": {},
   "source": [
    "## python postè¯·æ±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b72698-65cb-4398-9ae8-d280bf32d94b",
   "metadata": {},
   "source": [
    "### æœ¬åœ°postè¯·æ±‚ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26014c1-7055-4f65-8173-90c4575ec4bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"id\":\"chatcmpl-216\",\"object\":\"chat.completion\",\"created\":1722559669,\"model\":\"llama3:latest\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"I'm just an AI, a helpful assistant designed to assist and communicate with you in a way that's easy to understand and interact with. I can answer questions, provide information, generate ideas, and even have a conversation or tell a story. My purpose is to help make your life easier, more efficient, and more enjoyable!\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":67,\"total_tokens\":67}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "  \n",
    "url = 'http://127.0.0.1:11434/v1/chat/completions'    \n",
    "  \n",
    "# å‘é€JSONæ•°æ®  \n",
    "json_data = {\n",
    "    'model': 'llama3:latest',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ä½ æ˜¯è°ï¼Ÿ'\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "  \n",
    "# å‘é€POSTè¯·æ±‚ï¼Œå¹¶æŒ‡å®šjsonå‚æ•°  \n",
    "response = requests.post(url, json=json_data)  \n",
    "  \n",
    "print(response.status_code)  \n",
    "print(response.text)  #str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ed178-84c2-40fd-b8b2-b680dbcfee76",
   "metadata": {},
   "source": [
    "- å¢åŠ çŠ¶æ€ç å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78d6024-f058-4a54-b2c9-4274106dfb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-207\",\"object\":\"chat.completion\",\"created\":1722559818,\"model\":\"qwen2:latest\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"æˆ‘æ˜¯é˜¿é‡Œäº‘å¼€å‘çš„ä¸€æ¬¾è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚ä½œä¸ºä¸€ä¸ªé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæˆ‘çš„å…¨åæ˜¯â€œé€šä¹‰åƒé—®â€ï¼Œæ˜¯ç”±é˜¿é‡Œäº‘è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•å…¶ä»–æƒ³è¦äº†è§£çš„å†…å®¹ï¼Œæ¬¢è¿æ‚¨è¿›ä¸€æ­¥æé—®ï¼\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":23,\"completion_tokens\":55,\"total_tokens\":78}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from requests.exceptions import RequestException  \n",
    "  \n",
    "url = 'http://127.0.0.1:11434/v1/chat/completions'  \n",
    "# å‘é€JSONæ•°æ®  \n",
    "json_data = {\n",
    "    'model': 'qwen2:latest',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ä½ æ˜¯è°ï¼Ÿ'\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "  \n",
    "try:  \n",
    "    response = requests.post(url, json=json_data)  \n",
    "    response.raise_for_status()  # å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯200ï¼Œå°†æŠ›å‡ºHTTPErrorå¼‚å¸¸  \n",
    "    print(response.text)  \n",
    "except RequestException as e:  \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e768a-dd8c-4cb2-87b4-13ea56778f31",
   "metadata": {},
   "source": [
    "### æ–¹æ³•å°è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed7219c-a682-4af0-be83-2fcada319d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import json \n",
    "from requests.exceptions import RequestException  \n",
    "\n",
    "def local_llm(query,model_name=\"qwen2:latest\"):\n",
    "    url = 'http://127.0.0.1:11434/v1/chat/completions'  \n",
    "    # å‡è®¾æˆ‘ä»¬éœ€è¦å‘é€JSONæ•°æ®  \n",
    "    json_data = {\n",
    "        'model': model_name,\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': 'You are a helpful assistant.'\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': query\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "      \n",
    "    try:  \n",
    "        response = requests.post(url, json=json_data)  \n",
    "        response.raise_for_status()  # å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯200ï¼Œå°†æŠ›å‡ºHTTPErrorå¼‚å¸¸  \n",
    "        # print(response.text)\n",
    "        data_json = json.loads(response.text)\n",
    "        return data_json[\"choices\"][0][\"message\"]\n",
    "    except RequestException as e:  \n",
    "        print(e)\n",
    "    return {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58294c9-cbf8-4565-be1a-8a4666db14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸€åªçŒ«çœ‹è§å¦ä¸€åªçŒ«éª‘è‡ªè¡Œè½¦ï¼Œäºæ˜¯å®ƒä¹Ÿå»å­¦ï¼Œä½†æ˜¯æ€ä¹ˆä¹Ÿå­¦ä¸ä¼šã€‚å¦ä¸€åªçŒ«é—®ï¼šâ€œä½ ä¸ºä»€ä¹ˆè¿™ä¹ˆç¬¨ï¼Ÿâ€è¿™åªçŒ«å›ç­”è¯´ï¼Œâ€œæˆ‘å¯èƒ½ä¸Šè¾ˆå­æ¬ äº†ä»€ä¹ˆå€ºï¼Œè¿™è¾ˆå­åœ¨è¿˜ã€‚â€\n"
     ]
    }
   ],
   "source": [
    "res = local_llm(\"è®²ä¸ªç¬‘è¯\",model_name=\"qwen2:latest\")\n",
    "print(res['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06aac0b4-0078-4eef-b704-9eb1785d3acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "(Wait for it...)\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "Hope that made you laugh! ğŸ˜„ Do you want another one?\n"
     ]
    }
   ],
   "source": [
    "res = local_llm(\"è®²ä¸ªç¬‘è¯\",model_name=\"llama3:latest\")\n",
    "print(res['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58aad3dd-aac3-45ec-b55f-5f8c84f102f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜çš„å¥³æœ‹å‹æ€»æ˜¯ä¼šè¯´ï¼šâ€œæˆ‘çˆ±ä½ ï¼Œä½†æˆ‘æ›´çˆ±æˆ‘çš„ä»£ç â€ï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–ä»¬è®¤ä¸ºï¼Œä»£ç æ¯”äººæ›´åŠ ç¨³å®šã€å¯é ã€ä¸å®¹æ˜“å´©æºƒï¼ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "res = local_llm(\"è®²ä¸ªç¬‘è¯ï¼Œå…³äºç¨‹åºå‘˜çš„ï¼Œè¯·ä½¿ç”¨ä¸­æ–‡\",model_name=\"llama3:latest\")\n",
    "print(res['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07ba3b-f601-4fbb-a644-8acb41a5b82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addd0f18-9903-4341-93ce-f852999575e7",
   "metadata": {},
   "source": [
    "## WebUIè°ƒç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559f9c4-a2d2-421e-8207-923277e77de9",
   "metadata": {},
   "source": [
    "### Docker Desktopä¸‹è½½\n",
    "- https://docs.docker.com/desktop/release-notes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc303ee-0ff6-4169-a756-85536f15eff5",
   "metadata": {},
   "source": [
    "### openwebui\n",
    "- https://openwebui.com/\n",
    "- ä¸‹è½½dockeré•œåƒ\n",
    "- https://github.com/open-webui/open-webui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d9a75-b949-4748-b41a-8221c41534bf",
   "metadata": {},
   "source": [
    "### dockeré•œåƒå®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a62a2-32e9-4855-a59b-7fb58a4c0188",
   "metadata": {},
   "source": [
    "```\n",
    "GPU \n",
    "docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n",
    "\n",
    "CPU \n",
    "docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n",
    "\n",
    "è¿™ç§æ–¹å¼ä¸æ˜¯IPæ˜ å°„ï¼Œè€Œæ˜¯ç›´æ¥å°†ollamaæ–‡ä»¶æ˜ å°„åˆ°dockerä¸­ï¼Œè¿™ç§æ–¹å¼ä¸ä¼šå‡ºç°dockerä¸­æœåŠ¡å·²å¯åŠ¨ä½†å¤–éƒ¨wondowså´æ— æ³•è®¿é—®çš„ç°è±¡\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bae05-ec86-4005-ae4b-792ea0a33c55",
   "metadata": {},
   "source": [
    "å¸¸è§é—®é¢˜\n",
    "- æ­£å¸¸æƒ…å†µä¸‹ï¼Œåˆå­¦è€…ä¼šå¡åœ¨è¿™é‡Œï¼Œå‡ºç°å„ç§å¼‚å¸¸æƒ…å†µ\n",
    "- ä¸Šé¢çš„å®‰è£…æ–¹å¼åªæ˜¯é¿å…windowsç³»ç»Ÿçš„ç½‘ç»œé—®é¢˜ï¼Œmacä¸Šçš„åŒå­¦ä¸å¿…å¦‚æ­¤ï¼Œä½†macä¸Šçš„dockerä¹Ÿæœ‰è‡ªèº«çš„ç½‘ç»œé—®é¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7efa5-a247-43fc-a04a-7f64802d9a2e",
   "metadata": {},
   "source": [
    "```\n",
    "If Ollama is on your computer, use this command:\n",
    "docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n",
    "\n",
    "To run Open WebUI with Nvidia GPU support, use this command:\n",
    "docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda\n",
    "\n",
    "\n",
    "\n",
    "If Ollama is on a Different Server, use this command:\n",
    "To connect to Ollama on another server, change the OLLAMA_BASE_URL to the server's URL:\n",
    "\n",
    "docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa246d-af56-48c9-9df2-1cbc2aa30a54",
   "metadata": {},
   "source": [
    "- é€šè¿‡apipost/postmanå¯ä»¥è®¿é—®ollamaï¼Œç¡®è®¤Ollamaæ­£åœ¨è¿è¡Œï¼Œä½†WebUIä¸è¯†åˆ«\n",
    "- è¿™æ˜¯WebUI Dockeråˆ›å»ºæ—¶çš„ç½‘ç»œæ–¹å¼å¯¼è‡´çš„ï¼Œä»¥open-webuiä¸ºä¾‹ \n",
    "- https://github.com/open-webui/open-webui#troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46de15-395b-4d91-816e-5ee2b5f2e0bf",
   "metadata": {},
   "source": [
    "### openwebuiè®¿é—®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9537d8-cdb5-45a1-b85a-c20330c59379",
   "metadata": {},
   "source": [
    "- å¯åŠ¨dockerå®ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6356957-4638-4244-9df1-d95c352ae3fc",
   "metadata": {},
   "source": [
    "<img src=\"img/ui_20240802093919.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848be929-7286-461e-b08d-c6416a4397f3",
   "metadata": {},
   "source": [
    "- http://localhost:3000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4790831-338b-4b34-a575-68b6c9aa9c23",
   "metadata": {},
   "source": [
    "<img src=\"img/set_20240802094043.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789ab3f-14fa-40f2-a6e1-8caeef3f9785",
   "metadata": {},
   "source": [
    "å…ˆæ‹‰å–æ¨¡å‹å†é€‰æ‹©æ¨¡å‹\n",
    "- è™½ç„¶ollamaå·²ç»ä¸‹è½½äº†æ¨¡å‹ï¼Œä½†æœ‰æ—¶å€™è¯¥webuiåªè¯†åˆ«åœ¨è‡ªå·±å¹³å°ä¸‹è½½çš„æ¨¡å‹\n",
    "- å‡ºç°æ­¤ç°è±¡çš„åŸå› ï¼Œå¤§æ¦‚ç‡æ˜¯ç½‘ç»œä¸ç•…å¯¼è‡´çš„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcdd69-9e4b-4609-8527-1abbf7a3bbab",
   "metadata": {},
   "source": [
    "<img src=\"img/ml_20240802094239.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e276f-d86a-4c59-b777-e24b5d53111c",
   "metadata": {},
   "source": [
    "æ­£å¸¸æƒ…å†µä¸‹ï¼Œæ¯”å¦‚ç½‘ç»œç•…é€šæ—¶ï¼Œå“ªæ€•ä¸ä¸‹è½½ä¹Ÿä¼šå±•ç¤ºä¸€ç³»åˆ—çš„å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810da92-651a-4655-97a4-ce7e3e424403",
   "metadata": {},
   "source": [
    "<img src=\"img/ui_20240802094646.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8c8c8-21d3-430e-a182-e1ccc4367210",
   "metadata": {},
   "source": [
    "### å¯¹è¯ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ddd4db-3a0a-49e1-81a9-2a589ac2f43c",
   "metadata": {},
   "source": [
    "<img src=\"img/shi_20240802095116.png\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac72ed-59d9-497f-b15c-ffa91492296e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ecb6755-e5ee-4a66-9260-41d6dc0d8134",
   "metadata": {},
   "source": [
    "### lobe chat ui\n",
    "- é€‰åšï¼Œæ ¹æ®è‡ªèº«æƒ…å†µï¼Œå°è¯•é˜…è¯»å®˜æ–¹è¯´æ˜æ–‡æ¡£ï¼Œç‹¬ç«‹å®Œæˆå®‰è£…éƒ¨ç½²\n",
    "  - é¦–å…ˆå°è¯•å®˜æ–¹æ–‡æ¡£å…¥æ‰‹ï¼Œä¸€æ­¥æ­¥æ“ä½œï¼Œå› ä¸ºè¿™æ˜¯ç¬¬ä¸€æ‰‹èµ„æ–™ï¼Œé¢è¯•ä¸­æœ‰ä¸€é¡¹åŠ åˆ†é¡¹æ˜¯è·Ÿè¸ªæœ€æ–°å‰æ²¿æŠ€æœ¯\n",
    "  - è‹¥å¤±è´¥ï¼Œåˆ™å°è¯•æœç´¢æˆ–è€…å…¶ä»–è§†é¢‘ç½‘ç«™(æ¯”å¦‚Bç«™)æœç´¢ç›¸å…³çš„æ•™ç¨‹\n",
    "  - å†å¤±è´¥ï¼Œè¯·æ•™è€å¸ˆï¼ŒåŒå­¦\n",
    "- https://lobehub.com/zh/docs/usage/features/local-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbe7e6-3a00-420e-9788-70b57e924133",
   "metadata": {},
   "source": [
    "## ChatGLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb3694-f8d2-42a8-87a8-aee203f3606b",
   "metadata": {},
   "source": [
    "### 9Bç³»åˆ—ç®€ä»‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d91bb-cafc-4bc3-bec8-2d8d17e0d0e8",
   "metadata": {},
   "source": [
    "```\n",
    "GLM-4-9B æ˜¯æ™ºè°± AI æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é¢„è®­ç»ƒæ¨¡å‹ GLM-4 ç³»åˆ—ä¸­çš„å¼€æºç‰ˆæœ¬ã€‚ \n",
    "\n",
    "åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç å’ŒçŸ¥è¯†ç­‰å¤šæ–¹é¢çš„æ•°æ®é›†æµ‹è¯„ä¸­ï¼Œ\n",
    "GLM-4-9B åŠå…¶äººç±»åå¥½å¯¹é½çš„ç‰ˆæœ¬ GLM-4-9B-Chat å‡è¡¨ç°å‡ºè¾ƒé«˜çš„æ€§èƒ½ã€‚ \n",
    "\n",
    "é™¤äº†èƒ½è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒGLM-4-9B-Chat è¿˜å…·å¤‡ç½‘é¡µæµè§ˆã€ä»£ç æ‰§è¡Œã€\n",
    "è‡ªå®šä¹‰å·¥å…·è°ƒç”¨ï¼ˆFunction Callï¼‰å’Œé•¿æ–‡æœ¬æ¨ç†ï¼ˆæ”¯æŒæœ€å¤§ 128K ä¸Šä¸‹æ–‡ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚ \n",
    "\n",
    "æœ¬ä»£æ¨¡å‹å¢åŠ äº†å¤šè¯­è¨€æ”¯æŒï¼Œæ”¯æŒåŒ…æ‹¬æ—¥è¯­ï¼ŒéŸ©è¯­ï¼Œå¾·è¯­åœ¨å†…çš„ 26 ç§è¯­è¨€ã€‚\n",
    "æˆ‘ä»¬è¿˜æ¨å‡ºäº†æ”¯æŒ 1M ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆçº¦ 200 ä¸‡ä¸­æ–‡å­—ç¬¦ï¼‰çš„æ¨¡å‹ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe97ef-7577-4f82-b1d8-594422a7c9e9",
   "metadata": {},
   "source": [
    "<img src=\"img/glm_20240802114923.jpg\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695e301-190e-4894-9987-1cc316713a9c",
   "metadata": {},
   "source": [
    "<img src=\"img/glm_20240802110632.jpg\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24bcb0-d864-4c1c-9372-a3a880dc0361",
   "metadata": {},
   "source": [
    "### è¯„ä¼°æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45999800-8ba7-4926-a787-175811668805",
   "metadata": {},
   "source": [
    "- MMLU(æ ¸å¿ƒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffe73b-c987-43d5-9242-d9976410d32c",
   "metadata": {},
   "source": [
    "```\n",
    "Massive è‹±/ËˆmÃ¦sÉªv/ ç¾/ËˆmÃ¦sÉªv/  adj.å¤§é‡çš„ï¼Œå·¨å¤§çš„ï¼Œå¤§è§„æ¨¡çš„ï¼›\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7192fd-3bff-4acc-b36d-9b57cab015b4",
   "metadata": {},
   "source": [
    "```\n",
    "å«ä¹‰ï¼š\n",
    "MMLUï¼ˆMassive Multitask Language Understandingï¼‰åŸºå‡†æµ‹è¯•æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šç§è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å®ƒé€šå¸¸åŒ…å«ä¸€ç³»åˆ—å¤šæ ·åŒ–çš„ä»»åŠ¡ï¼Œå¦‚é˜…è¯»ç†è§£ã€å¸¸è¯†æ¨ç†ã€æ–‡æœ¬åˆ†ç±»ç­‰ï¼Œä»¥å…¨é¢è¡¡é‡æ¨¡å‹çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448d06a-9c99-4da5-904e-b690a6959ecc",
   "metadata": {},
   "source": [
    "```\n",
    "ç‰¹ç‚¹ï¼š\n",
    "å¤šä»»åŠ¡ï¼šæ¶µç›–å¤šç§è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ã€‚\n",
    "å¹¿æ³›è¦†ç›–ï¼šèƒ½å¤Ÿè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98ac40-3217-4c40-b3cb-e63f91bd892e",
   "metadata": {},
   "source": [
    "- C-Eval(ä¸­æ–‡)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d8c86-1809-4100-bb98-417a0061b87c",
   "metadata": {},
   "source": [
    "```\n",
    "å«ä¹‰ï¼š\n",
    "C-Evalæ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸­æ–‡å¤§æ¨¡å‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›è¯„ä¼°åŸºå‡†ã€‚\n",
    "å®ƒåŒ…å«è¦†ç›–äººæ–‡ã€ç¤¾ç§‘ã€ç†å·¥ç­‰å¤šä¸ªå­¦ç§‘æ–¹å‘çš„é¢˜ç›®ï¼Œ\n",
    "æ—¨åœ¨æµ‹è¯•æ¨¡å‹åœ¨çŸ¥è¯†å‹ä»»åŠ¡å’Œæ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d2e15-414d-45e3-b9d9-83dbfc7724a1",
   "metadata": {},
   "source": [
    "```\n",
    "ç‰¹ç‚¹ï¼š\n",
    "é’ˆå¯¹æ€§å¼ºï¼šä¸“æ³¨äºä¸­æ–‡å¤§æ¨¡å‹çš„è¯„ä¼°ã€‚\n",
    "å¹¿æ³›è¦†ç›–ï¼šåŒ…å«å¤šä¸ªå­¦ç§‘æ–¹å‘çš„é¢˜ç›®ã€‚\n",
    "åŒºåˆ†åº¦é«˜ï¼šèƒ½å¤ŸåŒºåˆ†æ¨¡å‹åœ¨çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ä¸Šçš„å¼ºå¼±ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f3d9b-a63a-4424-896c-15fa638a0f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2c27e26-bb2b-4be3-9fe7-9a408f61bc8d",
   "metadata": {},
   "source": [
    "### ç¡¬ä»¶é…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037af0d-2170-4dfd-a612-0e669d0afadb",
   "metadata": {},
   "source": [
    "- ä¾è¾“å…¥é•¿åº¦å»é€‰é…ç½®ï¼Œé»˜è®¤8Kè¾“å…¥ï¼Œé€‰24Gæ˜¾å­˜\n",
    "- é‡åŒ–ä¸ºINT4åï¼Œ8Kè¾“å…¥åœ¨12Gæ˜¾å­˜ä¸Šå°±å¯ä»¥è¿è¡Œï¼Œè¿™ä¹Ÿæ˜¯æœ¬åœ°è¿è¡Œé€šå¸¸åšé‡åŒ–çš„åŸå› "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6b0de-c3b1-41cd-b1fd-bec1ed2c75bd",
   "metadata": {},
   "source": [
    "è¿™é‡Œé»˜è®¤æ˜¯8Kï¼Œæ‰€ä»¥è¦é€‰ä¸€ä¸ª24Gçš„æ˜¾å¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d788b9-b12b-4701-bcf4-b6535a43898e",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/glm_20240802115707.jpg\" style=\"margin-left: 0px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa911d-a863-4362-a8f5-2226b5fe328b",
   "metadata": {},
   "source": [
    "### ä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b641165-ec80-4a7b-a84a-ee94387e2d9a",
   "metadata": {},
   "source": [
    "APIè°ƒç”¨ç¤ºä¾‹ä¸‹è½½\n",
    "- https://github.com/THUDM/GLM-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19df30-2538-4fda-b0d9-bc2e313c9cd5",
   "metadata": {},
   "source": [
    "```\n",
    "git clone https://github.com/THUDM/GLM-4.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66015827-5bae-4335-8eaa-33405df3a3e3",
   "metadata": {},
   "source": [
    "æ¨¡å‹æ–‡ä»¶ä¸‹è½½\n",
    "- https://huggingface.co/THUDM/glm-4-9b-chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd8dd1-ba70-43ad-a882-427a9ec6a729",
   "metadata": {},
   "source": [
    "```\n",
    "apt install curl git\n",
    "curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "apt install git-lfs\n",
    "\n",
    "git lfs install\n",
    "cd /root/autodl-tmp\n",
    "nohup git clone https://www.modelscope.cn/models/ZhipuAI/glm-4-9b-chat.git >/tmp/git.log 2>&1 &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d5e9c-299c-4fca-adb3-ca8ccc8ec61f",
   "metadata": {},
   "source": [
    "### ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30379a-1b51-48e7-86f8-52302ef31fa7",
   "metadata": {},
   "source": [
    "- åŸç”ŸæœåŠ¡å™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14064ead-e7e3-4ccf-9b75-90469f32bdb2",
   "metadata": {},
   "source": [
    "```\n",
    "cd basic_demo\n",
    "pip install requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ab266-0b04-4d97-a951-220b35ba8ee3",
   "metadata": {},
   "source": [
    "- ç¤¾åŒºæœåŠ¡å™¨ï¼Œè¡¥å……å®‰è£…ï¼Œæˆ–è€…è¿è¡Œæ—¶ç¼ºå°‘ä»€ä¹ˆå°±å†å®‰è£…ä»€ä¹ˆ,æ¯”å¦‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f153b-3797-4129-bdf2-23f5eca8c38c",
   "metadata": {},
   "source": [
    "```\n",
    "pip install uvicorn\n",
    "pip install vllm\n",
    "pip install sse_starlette\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8509b5-f218-46a1-b59f-d280f7117f1d",
   "metadata": {},
   "source": [
    "### Uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f934e-6af3-4fe4-8b8a-1b6895ff0f91",
   "metadata": {},
   "source": [
    "```\n",
    "Uvicorn æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ ASGIï¼ˆAsynchronous Server Gateway Interfaceï¼‰æœåŠ¡å™¨ï¼Œå®ƒç”¨äºè¿è¡Œ Python 3.7+ ç¼–å†™çš„å¼‚æ­¥ Web åº”ç”¨ç¨‹åºã€‚ASGI æ˜¯ä¸€ç§æ ‡å‡†ï¼Œå…è®¸ Python æ¡†æ¶å’ŒæœåŠ¡å™¨ä¹‹é—´å¼‚æ­¥é€šä¿¡ï¼Œæ”¯æŒ WebSocket å’Œ HTTP/2 ç­‰ç°ä»£ç½‘ç»œåè®®ã€‚Uvicorn å› å…¶é«˜æ€§èƒ½å’Œæ˜“ç”¨æ€§è€Œå¹¿å—æ¬¢è¿ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤„ç†å¤§é‡å¹¶å‘è¿æ¥æˆ–éœ€è¦é«˜æ€§èƒ½çš„å¼‚æ­¥ Web åº”ç”¨ç¨‹åºä¸­\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd04cb3-3aed-4ffd-b731-642b9d2bfc87",
   "metadata": {},
   "source": [
    "### vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b015db-2e29-4914-9506-14623d796d0e",
   "metadata": {},
   "source": [
    "- vLLMåº”ç”¨åœºæ™¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310f604-179b-433a-b7ff-62bd2265eb93",
   "metadata": {},
   "source": [
    "```\n",
    "vLLMé€‚ç”¨äºéœ€è¦é«˜æ•ˆå¤§æ¨¡å‹æ¨ç†çš„å„ç§åœºæ™¯ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€èŠå¤©æœºå™¨äººã€æ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡vLLMï¼Œå¼€å‘è€…å¯ä»¥è½»æ¾åœ°å®ç°é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿçš„æ¨¡å‹æ¨ç†æœåŠ¡ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614f769-88c3-46f4-b727-84635c9fc3b3",
   "metadata": {},
   "source": [
    "- vLLMçš„ç‰¹ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca650722-bb60-4606-9e8a-d147b55bdc57",
   "metadata": {},
   "source": [
    "```\n",
    "Paged Attentionï¼švLLMé¦–æ¬¡æå‡ºå¹¶å®ç°äº†Paged Attentionç®—æ³•ï¼Œè¯¥ç®—æ³•å€Ÿé‰´äº†æ“ä½œç³»ç»Ÿçš„åˆ†é¡µç®¡ç†æ¦‚å¿µï¼Œå°†è¿ç»­çš„é”®å€¼ç¼“å­˜ï¼ˆKV Cacheï¼‰åˆ†æ•£å­˜å‚¨ï¼Œä»¥å‡å°‘æ˜¾å­˜çš„ä¸å¿…è¦å ç”¨ï¼Œæé«˜æ•´ä½“æ€§èƒ½ã€‚\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a4650-fcd2-44d5-bb1f-890ffd40756a",
   "metadata": {},
   "source": [
    "```\n",
    "Continuous Batchingï¼švLLMé€šè¿‡è¿ç»­æ‰¹æ¬¡å¤„ç†ï¼ˆContinuous Batchingï¼‰ç­–ç•¥ï¼Œå³åœ¨ç”Ÿæˆä¸€ä¸ªtokenåç«‹å³å®‰æ’ä¸‹ä¸€æ‰¹è¯·æ±‚ï¼Œæ¥æå‡æ¨ç†æ•ˆç‡ã€‚è¿™ç§ç­–ç•¥å…è®¸vLLMåœ¨æ¯ä¸€è½®è¿­ä»£ä¸­å¤„ç†ä¸åŒæ•°é‡çš„è¯·æ±‚ï¼ˆå³batch sizeä¸å›ºå®šï¼‰ï¼Œä»è€Œæœ€å¤§åŒ–ååé‡ã€‚\n",
    "å¤šç§ä¼˜åŒ–æŠ€æœ¯ï¼š\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eecc7c-4072-41b6-be7a-58757ad73b9d",
   "metadata": {},
   "source": [
    "```\n",
    "vLLMè¿˜æ”¯æŒé‡åŒ–ï¼ˆå¦‚GPTQã€AWQã€SqueezeLLMã€FP8 KV Cacheç­‰ï¼‰ã€Tensor Parallelismã€é«˜æ€§èƒ½CUDA kernelç­‰åŠŸèƒ½ï¼Œä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†æ€§èƒ½ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36647f3-5f11-465d-8187-1b1dd353b8d3",
   "metadata": {},
   "source": [
    "### æœåŠ¡å¯åŠ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f020e-1bfb-4c97-a116-631a9aa44869",
   "metadata": {},
   "source": [
    "```\n",
    "cd /root/autodl-tmp/GLM-4/basic_demo\n",
    "CUDA_VISIBLE_DEVICES=0 python openai_api_server.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd764293-30e5-4860-a92f-ff31b45f3697",
   "metadata": {},
   "source": [
    "- æ­£å¸¸å¯åŠ¨æ—¥å¿—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c16437-2796-4950-8f12-801d35f8d6c3",
   "metadata": {},
   "source": [
    "```\n",
    "# CUDA_VISIBLE_DEVICES=0 python openai_api_server.py\n",
    "INFO 08-03 13:26:47 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/root/autodl-tmp/glm-4-9b-chat', speculative_config=None, tokenizer='/root/autodl-tmp/glm-4-9b-chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/root/autodl-tmp/glm-4-9b-chat, use_v2_block_manager=False, enable_prefix_caching=False)\n",
    "WARNING 08-03 13:26:47 tokenizer.py:129] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.\n",
    "INFO 08-03 13:26:48 model_runner.py:680] Starting to load model /root/autodl-tmp/glm-4-9b-chat...\n",
    "Loading safetensors checkpoint shards:   0% Completed | 0/10 [00:00<?, ?it/s]\n",
    "Loading safetensors checkpoint shards:  10% Completed | 1/10 [00:00<00:02,  3.07it/s]\n",
    "Loading safetensors checkpoint shards:  20% Completed | 2/10 [00:00<00:02,  2.73it/s]\n",
    "Loading safetensors checkpoint shards:  30% Completed | 3/10 [00:01<00:02,  2.60it/s]\n",
    "Loading safetensors checkpoint shards:  40% Completed | 4/10 [00:01<00:02,  2.55it/s]\n",
    "Loading safetensors checkpoint shards:  50% Completed | 5/10 [00:01<00:01,  2.51it/s]\n",
    "Loading safetensors checkpoint shards:  60% Completed | 6/10 [00:02<00:01,  2.50it/s]\n",
    "Loading safetensors checkpoint shards:  70% Completed | 7/10 [00:02<00:01,  2.60it/s]\n",
    "Loading safetensors checkpoint shards:  80% Completed | 8/10 [00:03<00:00,  2.60it/s]\n",
    "Loading safetensors checkpoint shards:  90% Completed | 9/10 [00:03<00:00,  2.55it/s]\n",
    "Loading safetensors checkpoint shards: 100% Completed | 10/10 [00:03<00:00,  2.51it/s]\n",
    "Loading safetensors checkpoint shards: 100% Completed | 10/10 [00:03<00:00,  2.56it/s]\n",
    "\n",
    "INFO 08-03 13:26:52 model_runner.py:692] Loading model weights took 17.5635 GB\n",
    "INFO 08-03 13:26:53 gpu_executor.py:102] # GPU blocks: 2962, # CPU blocks: 6553\n",
    "INFO:     Started server process [2335]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b6529-f202-4dc5-a0d0-cfbac11b33ad",
   "metadata": {},
   "source": [
    "### æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "- ä½¿ç”¨20Gæ˜¾å­˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd309c7-435a-40f4-91a7-4a83cde175a8",
   "metadata": {},
   "source": [
    "```\n",
    "# nvidia-smi\n",
    "Sat Aug  3 13:50:02 2024\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:B1:00.0 Off |                  Off |\n",
    "| 31%   27C    P8             30W /  450W |   20405MiB /  24564MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa59b4-dc1b-446f-9578-834ee7ecebcb",
   "metadata": {},
   "source": [
    "### è¯·æ±‚è®¿é—®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7cf84-944d-4171-8213-e625283a5c66",
   "metadata": {},
   "source": [
    "```\n",
    "# python openai_api_request.py\n",
    "ChatCompletion(id='chatcmpl-yGBEKQAw9qWAwd1R3BPhymc6njmxH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='å–µå–µå–µï¼Œæˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ', role='assistant', function_call=None, tool_calls=None))], created=1722664484, model='glm-4', object='chat.completion', service_tier=None, system_fingerprint='fp_j98jzQ2E4', usage=CompletionUsage(completion_tokens=19, prompt_tokens=47, total_tokens=66))\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a363d3-ac29-47fd-abdc-b575d047022d",
   "metadata": {},
   "source": [
    "### è¯·æ±‚APIè§£æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a2bf9-ad58-4353-aca1-46d4b390099a",
   "metadata": {},
   "source": [
    "- ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7ebf7-c132-4ad5-97fc-5188733c5117",
   "metadata": {},
   "source": [
    "```\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd0a0d-29fa-46b7-9c9e-38143bea25d1",
   "metadata": {},
   "source": [
    "- å¯¹è¯ä»£ç ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0082af-ddc9-4e99-82bc-325d0251453e",
   "metadata": {},
   "source": [
    "```\n",
    "from openai import OpenAI\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000/v1/\"\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=base_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068ab26-0aec-4ddd-ad4f-764a83e51b7c",
   "metadata": {},
   "source": [
    "```\n",
    "def simple_chat(use_stream=False):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"è¯·åœ¨ä½ è¾“å‡ºçš„æ—¶å€™éƒ½å¸¦ä¸Šâ€œå–µå–µå–µâ€ä¸‰ä¸ªå­—ï¼Œæ”¾åœ¨å¼€å¤´ã€‚\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ä½ æ˜¯è°\"\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=messages,\n",
    "        stream=use_stream,\n",
    "        max_tokens=256,\n",
    "        temperature=0.4,\n",
    "        presence_penalty=1.2,\n",
    "        top_p=0.8,\n",
    "    )\n",
    "    if response:\n",
    "        if use_stream:\n",
    "            for chunk in response:\n",
    "                print(chunk)\n",
    "        else:\n",
    "            print(response)\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    simple_chat(use_stream=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c53e5-a54a-4033-82c3-d501c1411e22",
   "metadata": {},
   "source": [
    "### æœåŠ¡å¯åŠ¨ä»£ç å…³é”®é…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73f94b-bd33-4e75-8b61-13e7b0cc982d",
   "metadata": {},
   "source": [
    "- æ¨¡å‹é…ç½®è·¯å¾„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcbfd06-8d17-4955-b7f7-6bc2a7d7e67b",
   "metadata": {},
   "source": [
    "```\n",
    "MODEL_PATH = os.environ.get('MODEL_PATH', 'THUDM/glm-4-9b-chat')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864d525-94c9-4682-a3d9-6a6c89992937",
   "metadata": {},
   "source": [
    "- vllméƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3defa3c-e37a-4b64-b282-3e33c3e7bcc9",
   "metadata": {},
   "source": [
    "```\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "    engine_args = AsyncEngineArgs(\n",
    "        model=MODEL_PATH,\n",
    "        tokenizer=MODEL_PATH,\n",
    "        # å¦‚æœä½ æœ‰å¤šå¼ æ˜¾å¡ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®æˆä½ çš„æ˜¾å¡æ•°é‡\n",
    "        tensor_parallel_size=1,\n",
    "        dtype=\"bfloat16\",\n",
    "        trust_remote_code=True,\n",
    "        # å ç”¨æ˜¾å­˜çš„æ¯”ä¾‹ï¼Œè¯·æ ¹æ®ä½ çš„æ˜¾å¡æ˜¾å­˜å¤§å°è®¾ç½®åˆé€‚çš„å€¼ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ çš„æ˜¾å¡æœ‰80Gï¼Œæ‚¨åªæƒ³ä½¿ç”¨24Gï¼Œè¯·æŒ‰ç…§24/80=0.3è®¾ç½®\n",
    "        gpu_memory_utilization=0.9,\n",
    "        enforce_eager=True,\n",
    "        worker_use_ray=False,\n",
    "        engine_use_ray=False,\n",
    "        disable_log_requests=True,\n",
    "        max_model_len=MAX_MODEL_LENGTH,\n",
    "    )\n",
    "    engine = AsyncLLMEngine.from_engine_args(engine_args)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fcfe2-c334-4bb9-a552-e4bc6f4ea859",
   "metadata": {},
   "source": [
    "- FastAPIæä¾›æ¥å£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca9a40-8311-4953-953a-448ee7622649",
   "metadata": {},
   "source": [
    "```\n",
    "app = FastAPI(lifespan=lifespan)\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c6a0f-f8a7-4f23-8015-4dc191746216",
   "metadata": {},
   "source": [
    "```\n",
    "uvicorn.run(app, host='0.0.0.0', port=8000, workers=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee79ed",
   "metadata": {},
   "source": [
    "GLM-4-9B æ˜¯æ™ºè°± AI æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é¢„è®­ç»ƒæ¨¡å‹ GLM-4 ç³»åˆ—ä¸­çš„å¼€æºç‰ˆæœ¬ã€‚ åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç å’ŒçŸ¥è¯†ç­‰å¤šæ–¹é¢çš„æ•°æ®é›†æµ‹è¯„ä¸­ï¼Œ GLM-4-9B åŠå…¶äººç±»åå¥½å¯¹é½çš„ç‰ˆæœ¬ GLM-4-9B-Chat å‡è¡¨ç°å‡ºè¶…è¶Š Llama-3-8B çš„å“è¶Šæ€§èƒ½ã€‚é™¤äº†èƒ½è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒGLM-4-9B-Chat è¿˜å…·å¤‡ç½‘é¡µæµè§ˆã€ä»£ç æ‰§è¡Œã€è‡ªå®šä¹‰å·¥å…·è°ƒç”¨ï¼ˆFunction Callï¼‰å’Œé•¿æ–‡æœ¬æ¨ç†ï¼ˆæ”¯æŒæœ€å¤§ 128K ä¸Šä¸‹æ–‡ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚æœ¬ä»£æ¨¡å‹å¢åŠ äº†å¤šè¯­è¨€æ”¯æŒï¼Œæ”¯æŒåŒ…æ‹¬æ—¥è¯­ï¼ŒéŸ©è¯­ï¼Œå¾·è¯­åœ¨å†…çš„ 26 ç§è¯­è¨€ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†æ”¯æŒ 1M ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆçº¦ 200 ä¸‡ä¸­æ–‡å­—ç¬¦ï¼‰çš„ GLM-4-9B-Chat-1M æ¨¡å‹å’ŒåŸºäº GLM-4-9B çš„å¤šæ¨¡æ€æ¨¡å‹ GLM-4V-9Bã€‚GLM-4V-9B å…·å¤‡ 1120 * 1120 é«˜åˆ†è¾¨ç‡ä¸‹çš„ä¸­è‹±åŒè¯­å¤šè½®å¯¹è¯èƒ½åŠ›ï¼Œåœ¨ä¸­è‹±æ–‡ç»¼åˆèƒ½åŠ›ã€æ„ŸçŸ¥æ¨ç†ã€æ–‡å­—è¯†åˆ«ã€å›¾è¡¨ç†è§£ç­‰å¤šæ–¹é¢å¤šæ¨¡æ€è¯„æµ‹ä¸­ï¼ŒGLM-4V-9B è¡¨ç°å‡ºè¶…è¶Š GPT-4-turbo-2024-04-09ã€Gemini 1.0 Proã€Qwen-VL-Max å’Œ Claude 3 Opus çš„å“è¶Šæ€§èƒ½ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
